{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jkXyGHa6WFz"
      },
      "outputs": [],
      "source": [
        "# import fitz\n",
        "\n",
        "# def extract_text_with_links(pdf_path):\n",
        "#     \"\"\"Extracts text with inline hyperlinks, handling multi-line links\"\"\"\n",
        "#     doc = fitz.open(pdf_path)\n",
        "#     full_text = []\n",
        "\n",
        "#     for page in doc:\n",
        "#         # Get all links first\n",
        "#         link_map = []\n",
        "#         for link in page.get_links():\n",
        "#             if link['kind'] == fitz.LINK_URI:\n",
        "#                 rect = fitz.Rect(link['from'])\n",
        "#                 link_map.append((rect, link['uri']))\n",
        "\n",
        "#         # Extract words with positions\n",
        "#         words = page.get_text(\"words\", sort=True)\n",
        "\n",
        "#         current_line = []\n",
        "#         current_links = set()\n",
        "\n",
        "#         for word in words:\n",
        "#             word_rect = fitz.Rect(word[:4])\n",
        "#             word_text = word[4]\n",
        "\n",
        "#             # Check for links intersecting this word\n",
        "#             for rect, uri in link_map:\n",
        "#                 if rect.intersects(word_rect):\n",
        "#                     current_links.add(uri)\n",
        "#                     break\n",
        "\n",
        "#             # Handle newlines\n",
        "#             if not current_line or word[0] > current_line[-1][2]:\n",
        "#                 if current_line:\n",
        "#                     full_text.append(_format_line(current_line, current_links))\n",
        "#                 current_line = [word]\n",
        "#                 current_links = set()\n",
        "#             else:\n",
        "#                 current_line.append(word)\n",
        "\n",
        "#         if current_line:\n",
        "#             full_text.append(_format_line(current_line, current_links))\n",
        "\n",
        "#     return \"\\n\".join(full_text)\n",
        "\n",
        "# def _format_line(words, links):\n",
        "#     \"\"\"Formats a line of text with links at end\"\"\"\n",
        "#     text = \" \".join(word[4] for word in words)\n",
        "#     if links:\n",
        "#         return f\"{text} [{' | '.join(links)}]\"\n",
        "#     return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rz5eDimxIam1"
      },
      "outputs": [],
      "source": [
        "# steps to train en_cweb_sm\n",
        "\n",
        "# get the training data\n",
        "\n",
        "# load the model\n",
        "\n",
        "\n",
        "# set up exapmples -> from training data\n",
        "\n",
        "# chooise the pipeline you want to train ('ner') -> named entity recognition in thie case\n",
        "\n",
        "# train the model\n",
        "\n",
        "\n",
        "# save the model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gD2v77QNBtu9"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import numpy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# as of now spacy==3.8.5 and numpy==2.0.2\n",
        "\n",
        "spacy.__version__\n",
        "numpy.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JJUwISNeb8B1",
        "outputId": "b033badc-7bba-409a-e8d6-dd17e157b20c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s6c95FJ-jIDo"
      },
      "outputs": [],
      "source": [
        "# one time\n",
        "# !python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuXDXEfeLPR3",
        "outputId": "c3c7943a-2652-4e02-966d-cec74be249f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Aachal\\n', 'Aadharsh\\n', 'Aadhavi\\n', 'Aadhira\\n', 'Aadidev\\n', 'Aadil\\n', 'Aadita\\n', 'Aaditya\\n', 'Aadiv\\n', 'Aadrik\\n', 'Aagney\\n', 'Aahan\\n', 'Aahana\\n', 'Aakaar\\n', 'Aakanksha\\n', 'Aakarsh\\n', 'Aakash\\n', 'Aakesh\\n', 'Aakriti\\n', 'Aakshi\\n', 'Aamra\\n', 'Aanchal\\n', 'Aanya\\n', 'Aarav\\n', 'Aariz\\n', 'Aarjay\\n', 'Aarna\\n', 'Aarush\\n', 'Aarushi\\n', 'Aarvi\\n', 'Aarya\\n', 'Aaryan\\n', 'Aashish\\n', 'Aashvi\\n', 'Aasim\\n', 'Aastha\\n', 'Aatish\\n', 'Aatreya\\n', 'Aayansh\\n', 'Aayod\\n', 'Aayush\\n', 'Aayushi\\n', 'Abbas\\n', 'Abdul\\n', 'Abdur\\n', 'Abeer\\n', 'Abhay\\n', 'Abhaya\\n', 'Abhaysinha\\n', 'Abhedhya\\n', 'Abhigya\\n', 'Abhijeet\\n', 'Abhijit\\n', 'Abhijoy\\n', 'Abhik\\n', 'Abhilash\\n', 'Abhilasha\\n', 'Abhimanyu\\n', 'Abhinandan\\n', 'Abhinav\\n', 'Abhishek\\n', 'Abhisikta\\n', 'Abhisumat\\n', 'Abhitha\\n', 'Abhoy\\n', 'Abhyuday\\n', 'Abinash\\n', 'Abrar\\n', 'Abuzar\\n', 'Acchutan\\n', 'Achintya\\n', 'Achyut\\n', 'Adarsh\\n', 'Adhiraj\\n', 'Adhrit\\n', 'Adhyan\\n', 'Adhyantika\\n', 'Adil\\n', 'Aditi\\n', 'Adity\\n', 'Aditya\\n', 'Advaita\\n', 'Advaith\\n', 'Advika\\n', 'Advith\\n', 'Adweta\\n', 'Adya\\n', 'Aeman\\n', 'Afzan\\n', 'Agampreet\\n', 'Agrim\\n', 'Ahad\\n', 'Ahilan\\n', 'Ahinsa\\n', 'Ahmad\\n', 'Ahnay\\n', 'Aija\\n', 'Aisha\\n', 'Aishwarya\\n', 'Ajaib\\n', 'Ajaipal\\n', 'Ajay\\n', 'Ajeet\\n', 'Ajit\\n', 'Ajith\\n', 'Akal\\n', 'Akanksha\\n', 'Akansha\\n', 'Akarsh\\n', 'Akarshita\\n', 'Akash\\n', 'Akhand\\n', 'Akhil\\n', 'Akhilesh\\n', 'Akhya\\n', 'Akshat\\n', 'Akshay\\n', 'Akshaya\\n', 'Akshayaguna\\n', 'Akshit\\n', 'Akshita\\n', 'Alagi\\n', 'Alani\\n', 'Ali\\n', 'Alim\\n', 'Alina\\n', 'Alka\\n', 'Alok\\n', 'Amaan\\n', 'Amaira\\n', 'Amala\\n', 'Aman\\n', 'Amar\\n', 'Amara\\n', 'Amarnath\\n', 'Amarpreet\\n', 'Ambar\\n', 'Amberlie\\n', 'Ambika\\n', 'Ambuj\\n', 'Amish\\n', 'Amisha\\n', 'Amit\\n', 'Amita\\n', 'Amitava\\n', 'Amitesh\\n', 'Amol\\n', 'Amrin\\n', 'Amrit\\n', 'Amrita\\n', 'Amruta\\n', 'Amrutha\\n', 'Amulya\\n', 'Ana\\n', 'Anadi\\n', 'Anaka\\n', 'Anand\\n', 'Ananya\\n', 'Anas\\n', 'Anavi\\n', 'Anchal\\n', 'Angad\\n', 'Anika\\n', 'Aniket\\n', 'Anikrishna\\n', 'Anil\\n', 'Anirban\\n', 'Aniruddh\\n', 'Aniruddha\\n', 'Anirudh\\n', 'Anish\\n', 'Anita\\n', 'Anitha\\n', 'Aniya\\n', 'Anjali\\n', 'Anjana\\n', 'Anjaneya\\n', 'Anjoo\\n', 'Anjuli\\n', 'Anjuman\\n', 'Ankit\\n', 'Ankita\\n', 'Ankolika\\n', 'Ankur\\n', 'Ankurjeet\\n', 'Ankush\\n', 'Anmol\\n', 'Annanya\\n', 'Annushka\\n', 'Anoop\\n', 'Anshika\\n', 'Anshit\\n', 'Anshu\\n', 'Anshul\\n', 'Anshuman\\n', 'Antara\\n', 'Anubha\\n', 'Anubhav\\n', 'Anubhuti\\n', 'Anuj\\n', 'Anukriti\\n', 'Anum\\n', 'Anunay\\n', 'Anupam\\n', 'Anupriya\\n', 'Anurag\\n', 'Anuraktika\\n', 'Anusha\\n', 'Anushi\\n', 'Anushka\\n', 'Anvi\\n', 'Anvit\\n', 'Anwar\\n', 'Anya\\n', 'Aparajita\\n', 'Aparna\\n', 'Aparsha\\n', 'Apoorva\\n', 'Apratim\\n', 'Apsara\\n', 'Apurv\\n', 'Apurva\\n', 'Apurwa\\n', 'Aqib\\n', 'Aqsa\\n', 'Arasi\\n', 'Aravind\\n', 'Archana\\n', 'Archi\\n', 'Archit\\n', 'Archita\\n', 'Ardhendu\\n', 'Areeb\\n', 'Areeba\\n', 'Ari\\n', 'Aria\\n', 'Arian\\n', 'Arihant\\n', 'Arish\\n', 'Aritra\\n', 'Arjun\\n', 'Armaan\\n', 'Arman\\n', 'Armoghan\\n', 'Arnab\\n', 'Arnav\\n', 'Arni\\n', 'Arpit\\n', 'Arpita\\n', 'Arsalan\\n', 'Arshad\\n', 'Arti\\n', 'Aruba\\n', 'Arun\\n', 'Arundhati\\n', 'Arunima\\n', 'Arunlal\\n', 'Arup\\n', 'Arushi\\n', 'Arvind\\n', 'Arya\\n', 'Aryaman\\n', 'Aryan\\n', 'Asad\\n', 'Ashal\\n', 'Asharudeen\\n', 'Ashay\\n', 'Ashik\\n', 'Ashirvad\\n', 'Ashish\\n', 'Ashit\\n', 'Ashmita\\n', 'Ashok\\n', 'Ashutosh\\n', 'Ashwani\\n', 'Ashwini\\n', 'Asif\\n', 'Asiya\\n', 'Asma\\n', 'Asmita\\n', 'Astha\\n', 'Asthana\\n', 'Astitva\\n', 'Asutosh\\n', 'Asvin\\n', 'Aswad\\n', 'Aswathy\\n', 'Aswin\\n', 'Ateequa\\n', 'Atharva\\n', 'Ati\\n', 'Atif\\n', 'Atiq\\n', 'Atishay\\n', 'Atul\\n', 'Aum\\n', 'Avanish\\n', 'Avi\\n', 'Avinash\\n', 'Aviral\\n', 'Avni\\n', 'Avnindra\\n', 'Ayaan\\n', 'Ayan\\n', 'Ayesha\\n', 'Ayla\\n', 'Ayush\\n', 'Ayushi\\n', 'Ayushman\\n', 'Azha\\n', 'Azmi\\n', 'Babitarani\\n', 'Babli\\n', 'Babu\\n', 'Baghyawati\\n', 'Balamurugan\\n', 'Balan\\n', 'Balbir\\n', 'Baldev\\n', 'Bandhul\\n', 'Banjeet\\n', 'Barkha\\n', 'Baruni\\n', 'Bashir\\n', 'Benoy\\n', 'Bhadrak\\n', 'Bhakti\\n', 'Bhama\\n', 'Bhanu\\n', 'Bhanumati\\n', 'Bhaskor\\n', 'Bhavani\\n', 'Bhavesh\\n', 'Bhavi\\n', 'Bhavika\\n', 'Bhavin\\n', 'Bhavini\\n', 'Bhavna\\n', 'Bhavya\\n', 'Bhavyesh\\n', 'Bhawana\\n', 'Bhawna\\n', 'Bhoopendra\\n', 'Bhrithi\\n', 'Bhumika\\n', 'Bhushan\\n', 'Bibhu\\n', 'Bibhuti\\n', 'Bidisha\\n', 'Biju\\n', 'Bilal\\n', 'Bimala\\n', 'Bina\\n', 'Bipasha\\n', 'Bipin\\n', 'Bishakha\\n', 'Bodhi\\n', 'Bokul\\n', 'Brahmaputra\\n', 'Brajesh\\n', 'Bramoni\\n', 'Brinda\\n', 'Chaaya\\n', 'Chahat\\n', 'Chaitali\\n', 'Chaitaly\\n', 'Chaitanya\\n', 'Chaithra\\n', 'Chaitya\\n', 'Chak\\n', 'Chakrapaani\\n', 'Chakrika\\n', 'Chaman\\n', 'Chameli\\n', 'Chanchal\\n', 'Chandana\\n', 'Chandani\\n', 'Chander\\n', 'Chandra\\n', 'Chandran\\n', 'Chandranshu\\n', 'Chandrasekhara\\n', 'Chandrashekhar\\n', 'Chandresh\\n', 'Charita\\n', 'Charu\\n', 'Charusila\\n', 'Charvitha\\n', 'Chasmum\\n', 'Chathresh\\n', 'Chavi\\n', 'Chavvi\\n', 'Chayan\\n', 'Chella\\n', 'Cherry\\n', 'Chetan\\n', 'Chetna\\n', 'Chhavi\\n', 'Chinmay\\n', 'Chinnamani\\n', 'Chintan\\n', 'Chirag\\n', 'Chiranjeev\\n', 'Chirayu\\n', 'Daiva\\n', 'Daiwik\\n', 'Daksh\\n', 'Daksha\\n', 'Dalaja\\n', 'Dalia\\n', 'Daljeet\\n', 'Daljit\\n', 'Damini\\n', 'Damyanti\\n', 'Danish\\n', 'Darika\\n', 'Darshil\\n', 'Darshit\\n', 'Darvesh\\n', 'Datarpreet\\n', 'Davneet\\n', 'Dayamai\\n', 'Dayita\\n', 'Debanjana\\n', 'Debashish\\n', 'Debesh\\n', 'Debjani\\n', 'Debolina\\n', 'Debyendu\\n', 'Deeksha\\n', 'Deep\\n', 'Deepa\\n', 'Deepak\\n', 'Deepali\\n', 'Deepanshu\\n', 'Deependra\\n', 'Deepika\\n', 'Deepinder\\n', 'Deepro\\n', 'Deepshikha\\n', 'Deeptimoyee\\n', 'Desh\\n', 'Dev\\n', 'Devadarshini\\n', 'Devadathan\\n', 'Devak\\n', 'Devansh\\n', 'Devanshu\\n', 'Devarya\\n', 'Devashish\\n', 'Devasree\\n', 'Devbrat\\n', 'Devdarshdeep\\n', 'Devendra\\n', 'Devesh\\n', 'Devi\\n', 'Devina\\n', 'Devirupa\\n', 'Devjeet\\n', 'Devpreet\\n', 'Devyanti\\n', 'Dhairya\\n', 'Dhananjay\\n', 'Dhanvin\\n', 'Dhariyithri\\n', 'Dharnitha\\n', 'Dharv\\n', 'Dhaval\\n', 'Dheeraj\\n', 'Dhir\\n', 'Dhriti\\n', 'Dhrsita\\n', 'Dhruv\\n', 'Dhruva\\n', 'Dhruvan\\n', 'Dhruvika\\n', 'Diganth\\n', 'Digraj\\n', 'Digvijay\\n', 'Diksha\\n', 'Dilip\\n', 'Dimpal\\n', 'Din\\n', 'Dinesh\\n', 'Dipa\\n', 'Dipankar\\n', 'Dipta\\n', 'Diptanshu\\n', 'Disha\\n', 'Divakar\\n', 'Divit\\n', 'Divya\\n', 'Divyam\\n', 'Divyansh\\n', 'Divyanshi\\n', 'Divyanshika\\n', 'Divyanshu\\n', 'Divyaraj\\n', 'Divyasree\\n', 'Diya\\n', 'Dolly\\n', 'Doshagya\\n', 'Drishith\\n', 'Drithi\\n', 'Dulal\\n', 'Durba\\n', 'Durga\\n', 'Durgesh\\n', 'Dushyant\\n', 'Dwijaa\\n', 'Eashan\\n', 'Edhitha\\n', 'Eegaiarasu\\n', 'Eelampirai\\n', 'Eesha\\n', 'Eesvari\\n', 'Ehan\\n', 'Ehsaan\\n', 'Ehtisham\\n', 'Eiravati\\n', 'Ekachakra\\n', 'Ekaja\\n', 'Ekani\\n', 'Ekanjeet\\n', 'Ekanpreet\\n', 'Ekanta\\n', 'Ekantika\\n', 'Ekaparnika\\n', 'Ekiya\\n', 'Eklavya\\n', 'Ekta\\n', 'Ektha\\n', 'Elamathi\\n', 'Elango\\n', 'Elavarasan\\n', 'Elavarasi\\n', 'Elili\\n', 'Elilvendan\\n', 'Elisaiyan\\n', 'Eshaan\\n', 'Eshal\\n', 'Eshan\\n', 'Eshana\\n', 'Eshma\\n', 'Eshwaritha\\n', 'Eta\\n', 'Fahad\\n', 'Faheem\\n', 'Faiyaz\\n', 'Faiz\\n', 'Faizan\\n', 'Falak\\n', 'Falguni\\n', 'Fanish\\n', 'Faraz\\n', 'Farhan\\n', 'Farid\\n', 'Farida\\n', 'Fariya\\n', 'Fatahun\\n', 'Fateh\\n', 'Fatima\\n', 'Fatma\\n', 'Fawaz\\n', 'Febin\\n', 'Forum\\n', 'Fullara\\n', 'Furqan\\n', 'Gaganjyot\\n', 'Gajaanan\\n', 'Gajapati\\n', 'Gajdant\\n', 'Gajendra\\n', 'Gajrup\\n', 'Galav\\n', 'Gana\\n', 'Ganak\\n', 'Ganesh\\n', 'Ganga\\n', 'GangaRam\\n', 'Ganika\\n', 'Garg\\n', 'Gargi\\n', 'Garima\\n', 'Garuda\\n', 'Garv\\n', 'Garvit\\n', 'Gathika\\n', 'Gaurangi\\n', 'Gaurav\\n', 'Gauri\\n', 'Gaurika\\n', 'Gaush\\n', 'Gaushik\\n', 'Gautam\\n', 'Gautami\\n', 'Gaveshan\\n', 'Gayanthika\\n', 'Gayathri\\n', 'Geet\\n', 'Geeta\\n', 'Geethanvitha\\n', 'Geethu\\n', 'Geetika\\n', 'Ghalib\\n', 'Girilal\\n', 'Gita\\n', 'Gitanshu\\n', 'Gitika\\n', 'Gnanam\\n', 'Gnanavalli\\n', 'Gnaneswar\\n', 'Gokul\\n', 'Goldy\\n', 'Gomathi\\n', 'GopalDas\\n', 'Gorakh\\n', 'Goswami\\n', 'Govind\\n', 'Govindam\\n', 'Grahish\\n', 'Grover\\n', 'Gulshan\\n', 'Gunamaalai\\n', 'Gunamalar\\n', 'Gunasekaran\\n', 'Gunasundari\\n', 'Gunav\\n', 'Gunbir\\n', 'Gundeep\\n', 'Guneet\\n', 'Gunjan\\n', 'Gunta\\n', 'Gurbachan\\n', 'Gurbaksh\\n', 'Gurbani\\n', 'Gurcharan\\n', 'Gurdayal\\n', 'Gurjot\\n', 'Gurkeerat\\n', 'Gurmeet\\n', 'Gurshaan\\n', 'Gurvansh\\n', 'Gyanvi\\n', 'Haarathi\\n', 'Haaris\\n', 'Haider\\n', 'Haifa\\n', 'Hajira\\n', 'Haleema\\n', 'Hammaad\\n', 'Hamood\\n', 'Hamsavahini\\n', 'Hanif\\n', 'Haniya\\n', 'Hansh\\n', 'Hanshitha\\n', 'Hansika\\n', 'Harbans\\n', 'Harbhajan\\n', 'Hari\\n', 'Hariharan\\n', 'Harikiran\\n', 'Harinakshi\\n', 'Harini\\n', 'Hariom\\n', 'Harishini\\n', 'Harita\\n', 'Harjas\\n', 'Harjot\\n', 'Harkirat\\n', 'Harleen\\n', 'Harmeet\\n', 'Harneet\\n', 'Harpal\\n', 'Harpreet\\n', 'Harsh\\n', 'Harsha\\n', 'Harshada\\n', 'Harshini\\n', 'Harshit\\n', 'Harshita\\n', 'Harshraj\\n', 'Harshvardhan\\n', 'Hartesh\\n', 'Hashir\\n', 'Hasina\\n', 'Hasni\\n', 'Hatchinghoi\\n', 'Havya\\n', 'Heena\\n', 'Hema\\n', 'Hemal\\n', 'Hemangini\\n', 'Hemani\\n', 'Hemanshu\\n', 'Hemant\\n', 'Hemavarun\\n', 'Hemlata\\n', 'Henish\\n', 'Herik\\n', 'Hershit\\n', 'Hetvi\\n', 'Hiba\\n', 'Himadri\\n', 'Himaksh\\n', 'Himani\\n', 'Himanshi\\n', 'Himanshu\\n', 'Himmat\\n', 'Hinal\\n', 'Hira\\n', 'Hiral\\n', 'Hiran\\n', 'Hiresh\\n', 'Hitesh\\n', 'Honey\\n', 'Hridyanshu\\n', 'Hrishab\\n', 'Hritika\\n', 'Humaid\\n', 'Humaira\\n', 'Hunny\\n', 'Husain\\n', 'Husna\\n', 'Hussain\\n', 'Ibhan\\n', 'Ibrahim\\n', 'Idhaya\\n', 'Idhayan\\n', 'Idhithri\\n', 'Idika\\n', 'Iditri\\n', 'Ifra\\n', 'Ijay\\n', 'Ijaya\\n', 'Ikshita\\n', 'Ilaiyaraja\\n', 'Ilakkiyan\\n', 'Ilamaran\\n', 'Ilanthirayan\\n', 'Ilavalagi\\n', 'Ilyas\\n', 'Imaad\\n', 'Imaduddeen\\n', 'Imara\\n', 'Inabat\\n', 'Indali\\n', 'Indebir\\n', 'Inderbir\\n', 'Inderdeep\\n', 'Inderpal\\n', 'Inderpreet\\n', 'Inderveer\\n', 'Indirveer\\n', 'Indora\\n', 'Indra\\n', 'Indrajit\\n', 'Indrani\\n', 'Indranil\\n', 'Indroneel\\n', 'Indu\\n', 'Inika\\n', 'Inimai\\n', 'Iqra\\n', 'Ira\\n', 'Iravaj\\n', 'Irfan\\n', 'Irumporai\\n', 'Irya\\n', 'Isha\\n', 'Ishan\\n', 'Ishani\\n', 'Ishank\\n', 'Ishanvi\\n', 'Ishika\\n', 'Ishita\\n', 'Ishivara\\n', 'Ishpreet\\n', 'Ishwa\\n', 'Ishya\\n', 'Iskand\\n', 'Ivaan\\n', 'Jag\\n', 'Jagadeesh\\n', 'Jaganath\\n', 'Jagath\\n', 'Jagrati\\n', 'Jagriti\\n', 'Jagvi\\n', 'Jahan\\n', 'Jahangeer\\n', 'Jahanvi\\n', 'Jahnavi\\n', 'Jai\\n', 'Jaiden\\n', 'Jaimini\\n', 'Jaipreet\\n', 'Jaisnavi\\n', 'Jaithra\\n', 'Jalender\\n', 'Jalil\\n', 'Jalsa\\n', 'Jami\\n', 'Jamir\\n', 'Janaki\\n', 'Janhvi\\n', 'Januja\\n', 'Janvi\\n', 'Janya\\n', 'Japan\\n', 'Japjot\\n', 'Japleen\\n', 'Japna\\n', 'Jarita\\n', 'Jasbir\\n', 'Jashveer\\n', 'Jasim\\n', 'Jaskaran\\n', 'Jaskeerat\\n', 'Jasleen\\n', 'Jasmeet\\n', 'Jasminder\\n', 'Jasmine\\n', 'Jasmit\\n', 'Jaspal\\n', 'Jaspinder\\n', 'Jaspreet\\n', 'Jasraj\\n', 'Jasvinder\\n', 'Jaswant\\n', 'Jauhari\\n', 'Jawad\\n', 'Jay\\n', 'Jaya\\n', 'Jaykant\\n', 'Jaypreet\\n', 'Jeet\\n', 'Jeevan\\n', 'Jeevika\\n', 'Jegathiswaran\\n', 'Jenamani\\n', 'Jeyahar\\n', 'Jhalak\\n', 'Jhansi\\n', 'Jhumpa\\n', 'Jigar\\n', 'Jiger\\n', 'Jigish\\n', 'Jigishu\\n', 'Jigisu\\n', 'Jigna\\n', 'Jignasa\\n', 'Jignesh\\n', 'Jigruksha\\n', 'Jimi\\n', 'Jitendra\\n', 'Jivani\\n', 'Jivathran\\n', 'Jivika\\n', 'Jiyan\\n', 'Jiyana\\n', 'Jiyu\\n', 'Jodha\\n', 'Joginder\\n', 'Johar\\n', 'Joshika\\n', 'Joshil\\n', 'Josna\\n', 'Joy\\n', 'Joyeeta\\n', 'Juhi\\n', 'Junaid\\n', 'Jyoti\\n', 'Jyotsana\\n', 'Kaanishk\\n', 'Kaberi\\n', 'Kabir\\n', 'Kaeya\\n', 'Kahan\\n', 'Kaif\\n', 'Kailash\\n', 'Kaira\\n', 'Kairav\\n', 'Kaivalya\\n', 'Kaiyen\\n', 'Kajal\\n', 'Kajol\\n', 'Kajori\\n', 'Kalaiarasi\\n', 'Kalaivani\\n', 'Kalapu\\n', 'Kalash\\n', 'Kalindee\\n', 'Kalindi\\n', 'Kalpana\\n', 'Kalpen\\n', 'Kalpi\\n', 'Kalyani\\n', 'Kamada\\n', 'Kamilah\\n', 'Kamini\\n', 'Kamran\\n', 'Kamya\\n', 'Kanan\\n', 'Kanayali\\n', 'Kanchan\\n', 'Kandarp\\n', 'Kanha\\n', 'Kanika\\n', 'Kanimoli\\n', 'Kanisha\\n', 'Kapil\\n', 'Karali\\n', 'Karam\\n', 'Karamjot\\n', 'Karampreet\\n', 'Karan\\n', 'Kareena\\n', 'Karishma\\n', 'Karmendra\\n', 'Karmjit\\n', 'Kartar\\n', 'Karthav\\n', 'Karthik\\n', 'Karthikeya\\n', 'Karthikeyan\\n', 'Kartik\\n', 'Kartikeya\\n', 'Kashif\\n', 'Kashish\\n', 'Kashvi\\n', 'Kasniya\\n', 'Kasturi\\n', 'Kausar\\n', 'Kaushambi\\n', 'Kaushik\\n', 'Kaushiki\\n', 'Kaustav\\n', 'Kaustubh\\n', 'Kavan\\n', 'Kavia\\n', 'Kavish\\n', 'Kavisha\\n', 'Kavya\\n', 'Kavyansh\\n', 'Kawaljit\\n', 'Kayalvizhi\\n', 'Keerat\\n', 'Kenisha\\n', 'Keshav\\n', 'Khaleel\\n', 'Khalid\\n', 'Khanak\\n', 'Khansa\\n', 'Khevna\\n', 'Khushboo\\n', 'Khushi\\n', 'Khushpreet\\n', 'Khushwant\\n', 'Kiaan\\n', 'Kiara\\n', 'Kimaya\\n', 'Kiran\\n', 'Kirandeep\\n', 'Kiranjot\\n', 'Kiranpreet\\n', 'Kirpal\\n', 'Kirti\\n', 'Kishan\\n', 'Kishen\\n', 'Kishor\\n', 'Kishore\\n', 'Kismet\\n', 'Kiyana\\n', 'Koel\\n', 'Koena\\n', 'Konkana\\n', 'Kori\\n', 'Koushik\\n', 'Krish\\n', 'Krisha\\n', 'Krishan\\n', 'Krishna\\n', 'Kritagya\\n', 'Kriti\\n', 'Kritika\\n', 'Kriyan\\n', 'Kshamya\\n', 'Kshitij\\n', 'Kuldeep\\n', 'Kulveer\\n', 'Kulwant\\n', 'Kunaal\\n', 'Kunal\\n', 'Kundalik\\n', 'Kundan\\n', 'Kushagra\\n', 'Kushal\\n', 'Kushan\\n', 'Kushwant\\n', 'Laboni\\n', 'Ladli\\n', 'Laiba\\n', 'Laith\\n', 'Lajita\\n', 'Laksh\\n', 'Lakshmi\\n', 'Lakshmika\\n', 'Lakshya\\n', 'Lalit\\n', 'Lata\\n', 'Latifah\\n', 'Lav\\n', 'Lavanya\\n', 'Laxmi\\n', 'Layth\\n', 'Leena\\n', 'Lekha\\n', 'Lekhraj\\n', 'Libni\\n', 'Lipika\\n', 'Lirthika\\n', 'Livdeep\\n', 'Livtar\\n', 'Liya\\n', 'Liyana\\n', 'Lohith\\n', 'Lopa\\n', 'Loshith\\n', 'Lotika\\n', 'Love\\n', 'Lubna\\n', 'Lucky\\n', 'Lusha\\n', 'Maanvi\\n', 'Maaran\\n', 'Maaz\\n', 'Machhan\\n', 'Madan\\n', 'Madhav\\n', 'Madhavaditya\\n', 'Madhavan\\n', 'Madhu\\n', 'Madhukar\\n', 'Madhuri\\n', 'Madhurima\\n', 'Madhusri\\n', 'Madhusudan\\n', 'Mahadev\\n', 'Mahant\\n', 'Maharth\\n', 'Mahasweta\\n', 'Mahato\\n', 'Mahek\\n', 'Mahendra\\n', 'Mahesh\\n', 'Mahi\\n', 'Mahika\\n', 'Mahima\\n', 'Mahin\\n', 'Mahindar\\n', 'Mahipal\\n', 'Mahit\\n', 'Mahua\\n', 'Maira\\n', 'Mairaz\\n', 'Majaz\\n', 'Malaimagal\\n', 'Mallesh\\n', 'Mallika\\n', 'Mamta\\n', 'Manali\\n', 'Manas\\n', 'Manaswini\\n', 'Manav\\n', 'Mandeep\\n', 'Mangai\\n', 'Mangal\\n', 'Mani\\n', 'Manideep\\n', 'Manikandan\\n', 'Manikuntala\\n', 'Maniraj\\n', 'Manish\\n', 'Manjeet\\n', 'Manju\\n', 'Manmohan\\n', 'Manorma\\n', 'Manshi\\n', 'Mansi\\n', 'Mansoon\\n', 'Manu\\n', 'Manush\\n', 'Manvendra\\n', 'Manvik\\n', 'Manya\\n', 'Martanda\\n', 'Matanga\\n', 'Maya\\n', 'Mayank\\n', 'Mayawati\\n', 'Mayukh\\n', 'Mayur\\n', 'Medha\\n', 'Meenal\\n', 'Meenu\\n', 'Meera\\n', 'Meet\\n', 'Meethun\\n', 'Megha\\n', 'Meghana\\n', 'Meghnad\\n', 'Mehak\\n', 'Mehar\\n', 'Mekhala\\n', 'Mila\\n', 'Milan\\n', 'Minakshi\\n', 'Minaxi\\n', 'Mini\\n', 'Miransh\\n', 'Miren\\n', 'Mirza\\n', 'Misha\\n', 'Mishti\\n', 'Mitali\\n', 'Mitika\\n', 'Mitra\\n', 'Mivan\\n', 'Mohan\\n', 'Mohandas\\n', 'Mohit\\n', 'Mohsin\\n', 'Moitreyee\\n', 'Moksh\\n', 'Moni\\n', 'Monica\\n', 'Monika\\n', 'Monish\\n', 'Monti\\n', 'Monu\\n', 'Moosvi\\n', 'Morad\\n', 'Motilal\\n', 'Mouni\\n', 'Moutushi\\n', 'Mridul\\n', 'Mrinal\\n', 'Mrinalini\\n', 'Mrithyunjay\\n', 'Mritunjay\\n', 'Mrityunjay\\n', 'Mubasshira\\n', 'Mudit\\n', 'Mudita\\n', 'Mugdha\\n', 'Mukesh\\n', 'Mukul\\n', 'Mukund\\n', 'Muneera\\n', 'Munir\\n', 'Munjal\\n', 'Munthala\\n', 'Murali\\n', 'Muralidhar\\n', 'Muskaan\\n', 'Muskan\\n', 'Mustafa\\n', 'Myra\\n', 'Mythili\\n', 'Nadeem\\n', 'Nagamani\\n', 'Nagarajan\\n', 'Nagesh\\n', 'Nageshwar\\n', 'Nageshwaran\\n', 'Nagjibhai\\n', 'Nagulan\\n', 'Nahid\\n', 'Naini\\n', 'Nainika\\n', 'Naitik\\n', 'Nakul\\n', 'Nalin\\n', 'Nallarasi\\n', 'Nallasivan\\n', 'Nallini\\n', 'Naman\\n', 'Namrata\\n', 'Nanda\\n', 'Nandini\\n', 'Nanku\\n', 'Naomika\\n', 'Narayan\\n', 'Narendra\\n', 'Naresh\\n', 'Nargis\\n', 'Narshimha\\n', 'Naseer\\n', 'Nashra\\n', 'Natwar\\n', 'Nav\\n', 'Naveen\\n', 'Navi\\n', 'Navin\\n', 'Navneet\\n', 'Navodit\\n', 'Navya\\n', 'Nawaz\\n', 'Naya\\n', 'Nayan\\n', 'Naziya\\n', 'Nazy\\n', 'Neelesh\\n', 'Neelja\\n', 'Neelu\\n', 'Neenu\\n', 'Neeraj\\n', 'Neesh\\n', 'Neetika\\n', 'Neha\\n', 'Neharika\\n', 'Nemi\\n', 'Nethaji\\n', 'Netra\\n', 'Nevaeh\\n', 'Nidhi\\n', 'Nidra\\n', 'Niesha\\n', 'Nihal\\n', 'Niharika\\n', 'Nihira\\n', 'Nikhil\\n', 'Nikit\\n', 'Nikita\\n', 'Nikith\\n', 'Nikunj\\n', 'Nila\\n', 'Nilambar\\n', 'Nilan\\n', 'Nilesh\\n', 'Nilima\\n', 'Nimesh\\n', 'Nimish\\n', 'Nimrat\\n', 'Nippu\\n', 'Niraj\\n', 'Niranjan\\n', 'Niranjana\\n', 'Nirja\\n', 'Nirlipta\\n', 'Nirmay\\n', 'Nirved\\n', 'Nirvi\\n', 'Nisha\\n', 'Nishad\\n', 'Nishan\\n', 'Nishant\\n', 'Nishchay\\n', 'Nishtha\\n', 'Nishu\\n', 'Nitara\\n', 'Niteesh\\n', 'Nitesh\\n', 'Nithin\\n', 'Nithisha\\n', 'Niti\\n', 'Nitikarsh\\n', 'Nitin\\n', 'Nitish\\n', 'Nitya\\n', 'Nivedita\\n', 'Nivika\\n', 'Niyam\\n', 'Noopur\\n', 'Noora\\n', 'Noorsaba\\n', 'Noyonika\\n', 'Nupur\\n', 'Nutan\\n', 'Nyra\\n', 'Odika\\n', 'Odoti\\n', 'Oeshi\\n', 'Ohm\\n', 'Oindrila\\n', 'Ojas\\n', 'Ojasvi\\n', 'Ojaswitha\\n', 'Olimani\\n', 'Om\\n', 'Omaja\\n', 'Omhari\\n', 'Omisha\\n', 'Omkant\\n', 'Omkar\\n', 'Omya\\n', 'Oni\\n', 'Oppilan\\n', 'Oresh\\n', 'Ornab\\n', 'Osha\\n', 'Osman\\n', 'Ovi\\n', 'Ovya\\n', 'Paakhi\\n', 'Paawan\\n', 'Padum\\n', 'Pahal\\n', 'Pakhi\\n', 'Palak\\n', 'Palash\\n', 'Palata\\n', 'Pallavi\\n', 'Panini\\n', 'Pankaj\\n', 'Pankhuri\\n', 'Param\\n', 'Paraman\\n', 'Paramjit\\n', 'Pardhuman\\n', 'Paresh\\n', 'Parijat\\n', 'Paritosh\\n', 'Parth\\n', 'Partho\\n', 'Paru\\n', 'Parul\\n', 'Pavalam\\n', 'Pavalan\\n', 'Pavan\\n', 'Pavani\\n', 'Pawan\\n', 'Phalgun\\n', 'Pinal\\n', 'Pinank\\n', 'Pinky\\n', 'Piyush\\n', 'Pooja\\n', 'Poonam\\n', 'Poornima\\n', 'Prabhakar\\n', 'Prabhas\\n', 'Prabhjot\\n', 'Prabhu\\n', 'Prabir\\n', 'Prabodh\\n', 'Prachi\\n', 'Pradeep\\n', 'Pradip\\n', 'Pradium\\n', 'Pradosh\\n', 'Pragati\\n', 'Pragun\\n', 'Pragya\\n', 'Prahlad\\n', 'Prajaktha\\n', 'Prajal\\n', 'Prajeeth\\n', 'Prajjwal\\n', 'Prakash\\n', 'Prakat\\n', 'Prakhar\\n', 'Prakharendra\\n', 'Prakhya\\n', 'Prakhyat\\n', 'Prakriti\\n', 'Pramukh\\n', 'Prana\\n', 'Pranab\\n', 'Pranad\\n', 'Pranauthi\\n', 'Pranav\\n', 'Pranay\\n', 'Praneel\\n', 'Pranidhi\\n', 'Pranjal\\n', 'Pranjali\\n', 'Pranusha\\n', 'Prarthana\\n', 'Prasanna\\n', 'Prashansi\\n', 'Prashant\\n', 'Prashasti\\n', 'Prasonjit\\n', 'Prasoon\\n', 'Prassanna\\n', 'Prastuti\\n', 'Prasun\\n', 'Prateek\\n', 'Pratham\\n', 'Prathmesh\\n', 'Pratibha\\n', 'Pratul\\n', 'Pratyush\\n', 'Pravan\\n', 'Praveen\\n', 'Pravi\\n', 'Prayadarshi\\n', 'Preetesh\\n', 'Preeti\\n', 'Prerit\\n', 'Prerna\\n', 'Prince\\n', 'Princy\\n', 'Prinit\\n', 'Prisha\\n', 'Pritha\\n', 'Pritul\\n', 'Privrata\\n', 'Priya\\n', 'Priyadarshan\\n', 'Priyadarshi\\n', 'Priyakanta\\n', 'Priyal\\n', 'Priyam\\n', 'Priyamvada\\n', 'Priyanka\\n', 'Priyanshi\\n', 'Priyanshu\\n', 'Priyesh\\n', 'Probal\\n', 'Pujesh\\n', 'Pulakesh\\n', 'Puneet\\n', 'Punya\\n', 'Purab\\n', 'Purav\\n', 'Purnanada\\n', 'Purnava\\n', 'Purnima\\n', 'Purushottam\\n', 'Puruvi\\n', 'Purvi\\n', 'Pushkar\\n', 'Pushti\\n', 'Putta\\n', 'Qadir\\n', 'Qarib\\n', 'Qushi\\n', 'Raashi\\n', 'Rabin\\n', 'Rachana\\n', 'Rachita\\n', 'Radha\\n', 'Radheyshyam\\n', 'Radhika\\n', 'Raghav\\n', 'Raghubeer\\n', 'Raghwendra\\n', 'Ragini\\n', 'Rahi\\n', 'Rahim\\n', 'Rahul\\n', 'Raj\\n', 'Rajamani\\n', 'Rajanikanta\\n', 'Rajat\\n', 'Rajata\\n', 'Rajendra\\n', 'Rajeshri\\n', 'Rajiv\\n', 'Rajkumar\\n', 'Rajneesh\\n', 'Raju\\n', 'Rajveer\\n', 'Rajvir\\n', 'Rakesh\\n', 'Rakhee\\n', 'Raksha\\n', 'Rakshan\\n', 'Rakshita\\n', 'Ram\\n', 'Rama\\n', 'Ramadoss\\n', 'Ramakrishna\\n', 'Raman\\n', 'Ramanakanth\\n', 'Ramandeep\\n', 'Ramesh\\n', 'Rameshwar\\n', 'Ramila\\n', 'Ramkrishna\\n', 'Rampratap\\n', 'Ramsundar\\n', 'Rana\\n', 'Ranbir\\n', 'Ranchi\\n', 'Rangan\\n', 'Ranjan\\n', 'Ranjeet\\n', 'Ranjeeta\\n', 'Ranu\\n', 'Ranveer\\n', 'Rashi\\n', 'Rashmi\\n', 'Ratan\\n', 'Rathik\\n', 'Rathindra\\n', 'Ratnesh\\n', 'Raunak\\n', 'Ravi\\n', 'Ravinandan\\n', 'Ravinderpreet\\n', 'Ravisankar\\n', 'Reghu\\n', 'Rehman\\n', 'Rekha\\n', 'Renu\\n', 'Reshami\\n', 'Reva\\n', 'Revan\\n', 'Revanth\\n', 'Ria\\n', 'Riaz\\n', 'Richa\\n', 'Riddhi\\n', 'Riddhiman\\n', 'Ridhaan\\n', 'Ridhan\\n', 'Ridhi\\n', 'Rishab\\n', 'Rishabh\\n', 'Rishav\\n', 'Rishi\\n', 'Rishika\\n', 'Rishiraj\\n', 'Rishit\\n', 'Rishu\\n', 'Ritank\\n', 'Ritesh\\n', 'Rithvik\\n', 'Ritika\\n', 'Ritu\\n', 'Ritul\\n', 'Rituraj\\n', 'Riya\\n', 'Riyan\\n', 'Rizwa\\n', 'Robin\\n', 'Rodas\\n', 'Rohan\\n', 'Rohit\\n', 'Rohith\\n', 'Roja\\n', 'Roma\\n', 'Romik\\n', 'Romil\\n', 'Romila\\n', 'Ronit\\n', 'Roshan\\n', 'Rouby\\n', 'Ruan\\n', 'Ruchi\\n', 'Ruchika\\n', 'Rudra\\n', 'Rudroneel\\n', 'Ruhi\\n', 'Rupal\\n', 'Rupali\\n', 'Rupanjali\\n', 'Rupeshwary\\n', 'Rupinder\\n', 'Ruqayyah\\n', 'Saanchi\\n', 'Saanvi\\n', 'Saawani\\n', 'Sabareesh\\n', 'Sabina\\n', 'Sabyasachi\\n', 'Sachin\\n', 'Saddam\\n', 'Sadguna\\n', 'Sadiq\\n', 'Sadiqa\\n', 'Sadique\\n', 'Sadiya\\n', 'Saeed\\n', 'Safa\\n', 'Safin\\n', 'Sagar\\n', 'Sagareka\\n', 'Sahaj\\n', 'Sahara\\n', 'Saharsh\\n', 'Sahil\\n', 'Sahiti\\n', 'Sai\\n', 'Saimadhav\\n', 'Sairam\\n', 'Saiya\\n', 'Sajan\\n', 'Sajani\\n', 'Sajmi\\n', 'Saket\\n', 'Saksham\\n', 'Sakshi\\n', 'Salmavati\\n', 'Saloni\\n', 'Samara\\n', 'Samardh\\n', 'Samarth\\n', 'Samath\\n', 'Samay\\n', 'Sameeksha\\n', 'Sameer\\n', 'Samriddhi\\n', 'Samta\\n', 'Sana\\n', 'Sanam\\n', 'Sandeep\\n', 'Sandhya\\n', 'Sangeeta\\n', 'Sangeeth\\n', 'Sania\\n', 'Sanjana\\n', 'Sanjay\\n', 'Sanjeeda\\n', 'Sanjeev\\n', 'Sanjit\\n', 'Sankalp\\n', 'Sanket\\n', 'Sanmeet\\n', 'Sanskar\\n', 'Sanskriti\\n', 'Santosh\\n', 'Sanu\\n', 'Sanyam\\n', 'Sapna\\n', 'Sara\\n', 'Saran\\n', 'Sarath\\n', 'Saravanan\\n', 'Sarika\\n', 'Sarin\\n', 'Sarthak\\n', 'Sarvanavel\\n', 'Sarvesh\\n', 'Sashwat\\n', 'Sasi\\n', 'Saswin\\n', 'Satendra\\n', 'Sathvik\\n', 'Sathwika\\n', 'Sathya\\n', 'Satnam\\n', 'Satvik\\n', 'Satwik\\n', 'Satwinder\\n', 'Satya\\n', 'Satyam\\n', 'Satyarth\\n', 'Satyendra\\n', 'Saudamini\\n', 'Saumile\\n', 'Saumya\\n', 'Saurabh\\n', 'Saurav\\n', 'Savan\\n', 'Sawan\\n', 'Sayan\\n', 'Sayeed\\n', 'Sayujya\\n', 'Seema\\n', 'Sehej\\n', 'Sejal\\n', 'Sekhar\\n', 'Senthil\\n', 'Seshikanth\\n', 'Sethuramani\\n', 'Shaad\\n', 'Shaan\\n', 'Shaarad\\n', 'Shabaj\\n', 'Shagufta\\n', 'Shagun\\n', 'Shahansha\\n', 'Shahid\\n', 'Shaileja\\n', 'Shailendra\\n', 'Shailesh\\n', 'Shailvi\\n', 'Shakaib\\n', 'Shakkil\\n', 'Shakti\\n', 'Shalin\\n', 'Shalini\\n', 'Shalu\\n', 'Shalvi\\n', 'Shambhavi\\n', 'Shamik\\n', 'Shamseer\\n', 'Shaniya\\n', 'Shantae\\n', 'Shantanu\\n', 'Shanti\\n', 'Shaqib\\n', 'Sharanya\\n', 'Shariq\\n', 'Sharique\\n', 'Sharuk\\n', 'Sharvan\\n', 'Sharvil\\n', 'Shashank\\n', 'Shashikala\\n', 'Shashwat\\n', 'Shatakshi\\n', 'Shaurya\\n', 'Shayak\\n', 'Shazia\\n', 'Sheesh\\n', 'Shekhar\\n', 'Sheshidhar\\n', 'Shiba\\n', 'Shibashis\\n', 'Shikha\\n', 'Shikhar\\n', 'Shilpa\\n', 'Shilpi\\n', 'Shipra\\n', 'Shirjon\\n', 'Shiromani\\n', 'Shirshendu\\n', 'Shiv\\n', 'Shivakumar\\n', 'Shivam\\n', 'Shivang\\n', 'Shivangi\\n', 'Shivani\\n', 'Shivansh\\n', 'Shivanshi\\n', 'Shivaya\\n', 'Shivin\\n', 'Shlok\\n', 'Shoaib\\n', 'Shraddha\\n', 'Shravya\\n', 'Shreepriya\\n', 'Shresht\\n', 'Shresth\\n', 'Shrestha\\n', 'Shresthi\\n', 'Shrey\\n', 'Shreya\\n', 'Shreyaansh\\n', 'Shreyans\\n', 'Shreyansh\\n', 'Shreyas\\n', 'Shreyash\\n', 'Shreyasi\\n', 'Shrikant\\n', 'Shrinivas\\n', 'Shrishti\\n', 'Shriya\\n', 'Shrut\\n', 'Shruti\\n', 'Shrutin\\n', 'Shubh\\n', 'Shubham\\n', 'Shubhang\\n', 'Shubhangi\\n', 'Shubhankar\\n', 'Shubhanshi\\n', 'Shubhanshu\\n', 'Shubhendu\\n', 'Shubhi\\n', 'Shubhkarman\\n', 'Shubho\\n', 'Shukant\\n', 'Shweta\\n', 'Shwetanshi\\n', 'Shyam\\n', 'Shyamal\\n', 'Shyamali\\n', 'Shyla\\n', 'Sidarth\\n', 'Siddh\\n', 'Siddhant\\n', 'Siddharth\\n', 'Siddhesh\\n', 'Siddhi\\n', 'Sidhi\\n', 'Sifat\\n', 'Sila\\n', 'Simaran\\n', 'Simran\\n', 'Siraj\\n', 'Sita\\n', 'Sitara\\n', 'Sitaram\\n', 'Sivaganesh\\n', 'Siya\\n', 'Smita\\n', 'Smitesh\\n', 'Smriti\\n', 'Sneha\\n', 'Snehal\\n', 'Snehil\\n', 'Snehill\\n', 'Snehit\\n', 'Snehlata\\n', 'Snigdha\\n', 'Snoopi\\n', 'Sohum\\n', 'Som\\n', 'Sona\\n', 'Sonal\\n', 'Soni\\n', 'Sonia\\n', 'Sonika\\n', 'Soniya\\n', 'Sonth\\n', 'Sonu\\n', 'Sony\\n', 'Soubhagya\\n', 'Soudeep\\n', 'Soumitra\\n', 'Soumya\\n', 'Soumyadeep\\n', 'Sourabh\\n', 'Sourav\\n', 'Souvik\\n', 'Sowjanya\\n', 'Srasti\\n', 'Sravan\\n', 'Sravani\\n', 'Sravya\\n', 'Sreekanth\\n', 'Sreelakshmi\\n', 'Sriansh\\n', 'Srijan\\n', 'Srijit\\n', 'Srikrishan\\n', 'Srishti\\n', 'Stalin\\n', 'Stuti\\n', 'Subash\\n', 'Subham\\n', 'Subhashini\\n', 'Subhashis\\n', 'Subhra\\n', 'Subodh\\n', 'Subrata\\n', 'Suchita\\n', 'Sudarsini\\n', 'Sudhakar\\n', 'Sudhanshu\\n', 'Sudheer\\n', 'Sudiksha\\n', 'Sudipto\\n', 'Sugathan\\n', 'Suhaas\\n', 'Suhail\\n', 'Suhani\\n', 'Suhasini\\n', 'Sujal\\n', 'Sujan\\n', 'Sujit\\n', 'Sujoy\\n', 'Sukirat\\n', 'Sukirti\\n', 'Sukrit\\n', 'Sukumaran\\n', 'Sulochana\\n', 'Sultan\\n', 'Sumaiya\\n', 'Suman\\n', 'Sumana\\n', 'Sumedh\\n', 'Sumeet\\n', 'Sumit\\n', 'Sunbir\\n', 'Sunil\\n', 'Sunish\\n', 'Sunny\\n', 'Suprabha\\n', 'Supriya\\n', 'Sura\\n', 'Suraj\\n', 'Surajit\\n', 'Suramya\\n', 'Surbhi\\n', 'Surendra\\n', 'Suresh\\n', 'Suri\\n', 'Surjeet\\n', 'Surya\\n', 'Suryakala\\n', 'Suryakant\\n', 'Suryansh\\n', 'Sushant\\n', 'Susheel\\n', 'Sushil\\n', 'Sushmita\\n', 'Susmithaa\\n', 'Sutej\\n', 'Suyash\\n', 'Suyesh\\n', 'Swapnil\\n', 'Swara\\n', 'Swarag\\n', 'Swarnava\\n', 'Swasti\\n', 'Swati\\n', 'Sweta\\n', 'Swinder\\n', 'Tabish\\n', 'Tahani\\n', 'Tahreem\\n', 'Talika\\n', 'Talin\\n', 'Tamanna\\n', 'Tanay\\n', 'Tanish\\n', 'Tanishq\\n', 'Tanishta\\n', 'Taniska\\n', 'Tanmay\\n', 'Tanmayi\\n', 'Tanpreet\\n', 'Tanu\\n', 'Tanupriya\\n', 'Tanveer\\n', 'Tanvi\\n', 'Tanya\\n', 'Tapan\\n', 'Tapas\\n', 'Tapasi\\n', 'Tapsee\\n', 'Tarak\\n', 'Taramla\\n', 'Tarana\\n', 'Tariq\\n', 'Tarique\\n', 'Tarun\\n', 'Tarushi\\n', 'Tashi\\n', 'Tavish\\n', 'Tegh\\n', 'Tej\\n', 'Tejas\\n', 'Thaanya\\n', 'Thangaraj\\n', 'Thanmayi\\n', 'Thanvi\\n', 'Thanya\\n', 'Tharun\\n', 'Thevan\\n', 'Thillaivanan\\n', 'Thirugnanam\\n', 'Thirukural\\n', 'Thirumal\\n', 'Tilakavati\\n', 'Tipu\\n', 'Toshit\\n', 'Trilochan\\n', 'Trinath\\n', 'Tripti\\n', 'Triveni\\n', 'Triya\\n', 'Tuhin\\n', 'Tuhina\\n', 'Tulshidas\\n', 'Turvi\\n', 'Tushar\\n', 'Tvarika\\n', 'Ubika\\n', 'Ucchal\\n', 'Udai\\n', 'Uday\\n', 'Udbhav\\n', 'Udisha\\n', 'Udit\\n', 'Udyati\\n', 'Ujjwal\\n', 'Ulagan\\n', 'Ulagarasan\\n', 'Ulhas\\n', 'Uma\\n', 'Umair\\n', 'Umaiza\\n', 'Umamaheshwara\\n', 'Umamaheshwari\\n', 'Umang\\n', 'Umayr\\n', 'Umesh\\n', 'Umme\\n', 'Unnati\\n', 'Unni\\n', 'Upadhriti\\n', 'Upamanyu\\n', 'Upasana\\n', 'Upasna\\n', 'Upma\\n', 'Urishilla\\n', 'Urmi\\n', 'Urmila\\n', 'Usman\\n', 'Uthman\\n', 'Utkarsh\\n', 'Utkarsha\\n', 'Utpal\\n', 'Utsav\\n', 'Uttam\\n', 'Uzair\\n', 'Vagisha\\n', 'Vaibhav\\n', 'Vaidyanathan\\n', 'Vaishali\\n', 'Vaishavi\\n', 'Vaishnavi\\n', 'Vaishvi\\n', 'Vamakshi\\n', 'Vamshi\\n', 'Vamsi\\n', 'Vandana\\n', 'Vandita\\n', 'Vangara\\n', 'Vansha\\n', 'Vanshi\\n', 'Vanshika\\n', 'Vanya\\n', 'Vardan\\n', 'Vardhamann\\n', 'Varenya\\n', 'Varenyam\\n', 'Varna\\n', 'Varnit\\n', 'Varsha\\n', 'Vartika\\n', 'Varun\\n', 'Vasana\\n', 'Vasatika\\n', 'Vashif\\n', 'Vasudha\\n', 'Vasundhara\\n', 'Vatsal\\n', 'Vatsalya\\n', 'Vaydish\\n', 'Vedang\\n', 'Vedanshi\\n', 'Vedanti\\n', 'Vedhika\\n', 'Veena\\n', 'Veer\\n', 'Veeramagal\\n', 'Veerendra\\n', 'Vengatesh\\n', 'Venkata\\n', 'Vera\\n', 'Vertika\\n', 'Viaan\\n', 'Vibha\\n', 'Vibhanshu\\n', 'Vidhi\\n', 'Vidit\\n', 'Vidul\\n', 'Vidushi\\n', 'Vidya\\n', 'Vidyadhar\\n', 'Vignesh\\n', 'Vigneshwaran\\n', 'Vihan\\n', 'Vijay\\n', 'Vijaypal\\n', 'Vijendra\\n', 'Vijna\\n', 'Vikas\\n', 'Vikash\\n', 'Vikram\\n', 'Viksya\\n', 'Vilas\\n', 'Vimal\\n', 'Vimala\\n', 'Vimlesh\\n', 'Vinay\\n', 'Vinaya\\n', 'Vineet\\n', 'Vineeta\\n', 'Vipasha\\n', 'Vipin\\n', 'Vipul\\n', 'Vir\\n', 'Viraj\\n', 'Virali\\n', 'Virat\\n', 'Virika\\n', 'Vishal\\n', 'Vishesh\\n', 'Vishnu\\n', 'Vishva\\n', 'Vishwa\\n', 'Vishwadeep\\n', 'Vishwanath\\n', 'Vishwas\\n', 'Viswaroopin\\n', 'Vivek\\n', 'Viviktha\\n', 'Vratanshi\\n', 'Vrishti\\n', 'Vritika\\n', 'Vritti\\n', 'Vyanjana\\n', 'Vyas\\n', 'Vyom\\n', 'Vyomini\\n', 'Wafa\\n', 'Waida\\n', 'Wakeeta\\n', 'Waleed\\n', 'Wali\\n', 'Wamika\\n', 'Warda\\n', 'Warhi\\n', 'Wasfia\\n', 'Wasil\\n', 'Watika\\n', 'Widisha\\n', 'Wishi\\n', 'Xalak\\n', 'Xiti\\n', 'Yachana\\n', 'Yachna\\n', 'Yadavi\\n', 'Yahvi\\n', 'Yajin\\n', 'Yaksh\\n', 'Yakshit\\n', 'Yakub\\n', 'Yanisha\\n', 'Yansh\\n', 'Yarah\\n', 'Yash\\n', 'Yashaswi\\n', 'Yashaswini\\n', 'Yashawini\\n', 'Yashica\\n', 'Yashika\\n', 'Yashoda\\n', 'Yashodhara\\n', 'Yashovardhan\\n', 'Yashpal\\n', 'Yashveer\\n', 'Yashvir\\n', 'Yashwant\\n', 'Yashwanth\\n', 'Yasti\\n', 'Yatharth\\n', 'Yauva\\n', 'Yauvani\\n', 'Yeram\\n', 'Yochana\\n', 'Yogansh\\n', 'Yogendra\\n', 'Yogesh\\n', 'Yogita\\n', 'Yoshita\\n', 'Yug\\n', 'Yukti\\n', 'Yumna\\n', 'Yunus\\n', 'Yusra\\n', 'Yusuf\\n', 'Yutika\\n', 'Yuvan\\n', 'Yuvraj\\n', 'Zahed\\n', 'Zahid\\n', 'Zaid\\n', 'Zain\\n', 'Zaina\\n', 'Zaineb\\n', 'Zaitra\\n', 'Zakariya\\n', 'Zamir\\n', 'Zansi\\n', 'Zara\\n', 'Zarna\\n', 'Zarrar\\n', 'Zayan\\n', 'Zayn\\n', 'Zeal\\n', 'Zeeshan\\n', 'Zian\\n', 'Zilmil\\n', 'Zinal\\n', 'Ziya\\n', 'Ziyad\\n', 'Zoha\\n', 'Zoheb\\n', 'Zoraiz\\n', 'Zoya\\n', 'Zufeshan\\n', 'Zunaira']\n"
          ]
        }
      ],
      "source": [
        "with open('first_name.txt', 'r') as f:\n",
        "    first_name = f.readlines()\n",
        "print(first_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcBSWImbLna5",
        "outputId": "d0b2f4ae-83a4-42fe-d405-69eb673f8495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Acharya\\n', 'Adhaulia\\n', 'Adhya\\n', 'Aenugu\\n', 'Afreen\\n', 'Afsar\\n', 'Aftab\\n', 'Agarawal\\n', 'Agarwal\\n', 'Agate\\n', 'Aggarwal\\n', 'Aggrawal\\n', 'Agrahari\\n', 'Agrawal\\n', 'Ahamad\\n', 'Ahluwalia\\n', 'Ahmad\\n', 'Ahmed\\n', 'Ahuja\\n', 'Aishwary\\n', 'Akhtar\\n', 'Akolkar\\n', 'Alam\\n', 'Aleem\\n', 'Ali\\n', 'Alwadhi\\n', 'Amble\\n', 'Anam\\n', 'Anand\\n', 'Andra\\n', 'Anjum\\n', 'Anne\\n', 'Ansari\\n', 'Anupama\\n', 'Anwar\\n', 'Apte\\n', 'Arif\\n', 'Arora\\n', 'Arya\\n', 'Ashraf\\n', 'Asija\\n', 'Asthana\\n', 'Ataher\\n', 'Athar\\n', 'Atri\\n', 'Attraa\\n', 'Atwal\\n', 'Aurora\\n', 'Awasthi\\n', 'Azam\\n', 'Azhar\\n', 'Azmi\\n', 'Babu\\n', 'Badal\\n', 'Badami\\n', 'Baddur\\n', 'Baghel\\n', 'Bahl\\n', 'Bahri\\n', 'Bai\\n', 'Bail\\n', 'Bains\\n', 'Bais\\n', 'Baiswar\\n', 'Bajaj\\n', 'Bajpai\\n', 'Bajwa\\n', 'Bakshi\\n', 'Bal\\n', 'Bala\\n', 'Balakrishnan\\n', 'Balan\\n', 'Balasubramanian\\n', 'Balay\\n', 'Bali\\n', 'Baliga\\n', 'Balkoty\\n', 'Balmiki\\n', 'Balot\\n', 'Bandi\\n', 'Banerjee\\n', 'Banik\\n', 'Bano\\n', 'Banothu\\n', 'Bansal\\n', 'Bapat\\n', 'Bapna\\n', 'Barad\\n', 'Barai\\n', 'Baral\\n', 'Baranwal\\n', 'Baria\\n', 'Barman\\n', 'Barnawal\\n', 'Barnwal\\n', 'Basak\\n', 'Bassi\\n', 'Basu\\n', 'Bath\\n', 'Batra\\n', 'Batta\\n', 'Bauri\\n', 'Bava\\n', 'Bawa\\n', 'Bedi\\n', 'Begam\\n', 'Begum\\n', 'Behera\\n', 'Behl\\n', 'Behura\\n', 'Behuria\\n', 'Belide\\n', 'Ben\\n', 'Bera\\n', 'Bhadauria\\n', 'Bhadauriya\\n', 'Bhadouriya\\n', 'Bhagat\\n', 'Bhakta\\n', 'Bhal\\n', 'Bhalla\\n', 'Bhandari\\n', 'Bharadwaj\\n', 'Bhardwaj\\n', 'Bhargava\\n', 'Bhasin\\n', 'Bhaskar\\n', 'Bhat\\n', 'Bhatia\\n', 'Bhatnagar\\n', 'Bhatt\\n', 'Bhattacharjee\\n', 'Bhattacharya\\n', 'Bhattacharyya\\n', 'Bhatti\\n', 'Bhavsar\\n', 'Bhorkhade\\n', 'Bhriguvanshi\\n', 'Bhukya\\n', 'Bhushan\\n', 'Bibi\\n', 'Bindal\\n', 'Bir\\n', 'Bisht\\n', 'Bistagond\\n', 'Biswas\\n', 'Boase\\n', 'Bobal\\n', 'Bora\\n', 'Borah\\n', 'Borde\\n', 'Borra\\n', 'Bose\\n', 'Brahmbhatt\\n', 'Brar\\n', 'Buch\\n', 'Bugalia\\n', 'Bumb\\n', 'Butala\\n', 'Cauhan\\n', 'Chacko\\n', 'Chad\\n', 'Chada\\n', 'Chadha\\n', 'Chahal\\n', 'Chakma\\n', 'Chakrabarti\\n', 'Chakrabortty\\n', 'Chakraborty\\n', 'Chana\\n', 'Chand\\n', 'Chanda\\n', 'Chandel\\n', 'Chander\\n', 'Chandra\\n', 'Chandran\\n', 'Char\\n', 'Chary\\n', 'Chatterjee\\n', 'Chaturvedi\\n', 'Chaubey\\n', 'Chaudhari\\n', 'Chaudhary\\n', 'Chaudhry\\n', 'Chaudhuri\\n', 'Chaudry\\n', 'Chauhan\\n', 'Chaurasia\\n', 'Chaurasiya\\n', 'Chavan\\n', 'Chawla\\n', 'Chechani\\n', 'Cheema\\n', 'Chellani\\n', 'Cherian\\n', 'Chetan\\n', 'Chhabra\\n', 'Chhateja\\n', 'Chhipa\\n', 'Chirag\\n', 'Chitranshi\\n', 'Chokshi\\n', 'Chopra\\n', 'Choubey\\n', 'Choudhary\\n', 'Choudhry\\n', 'Choudhury\\n', 'Chouhan\\n', 'Chowdhury\\n', 'Comar\\n', 'Contractor\\n', 'D’Alia\\n', 'Dada\\n', 'Dadarwal\\n', 'Dagade\\n', 'Dahiya\\n', 'Dahlan\\n', 'Dalal\\n', 'Dani\\n', 'Dar\\n', 'Dara\\n', 'Darshan\\n', 'Das\\n', 'Dasgupta\\n', 'Dash\\n', 'Dasila\\n', 'Dass\\n', 'Date\\n', 'Datta\\n', 'Dave\\n', 'Dayal\\n', 'De\\n', 'Debnath\\n', 'Deep\\n', 'Deo\\n', 'Deol\\n', 'Desabathula\\n', 'Desai\\n', 'Deshmukh\\n', 'Deshpande\\n', 'Dev\\n', 'Devan\\n', 'Devi\\n', 'Dewan\\n', 'Dey\\n', 'Dhaka\\n', 'Dhaliwal\\n', 'Dhamane\\n', 'Dhar\\n', 'Dhaulakhandi\\n', 'Dhawan\\n', 'Dhillon\\n', 'Dhiman\\n', 'Dhindhwal\\n', 'Dhingra\\n', 'Dhinoja\\n', 'Dhoni\\n', 'Dikshit\\n', 'Din\\n', 'Dinu\\n', 'Divan\\n', 'Dixit\\n', 'Doctor\\n', 'Dohrey\\n', 'Dora\\n', 'Doshi\\n', 'Dua\\n', 'Dube\\n', 'Dubey\\n', 'Dudeja\\n', 'Dugal\\n', 'Dugar\\n', 'Durgavansh\\n', 'Durgavanshi\\n', 'Dutt\\n', 'Dutta\\n', 'Dwevedi\\n', 'Dwivedi\\n', 'Dyal\\n', 'Edwin\\n', 'Fathima\\n', 'Fatima\\n', 'Fernandes\\n', 'Francis\\n', 'Gaba\\n', 'Gade\\n', 'Gadge\\n', 'Gaikwad\\n', 'Gakhar\\n', 'Gala\\n', 'Ganapathy\\n', 'Gandhi\\n', 'Ganesan\\n', 'Ganesh\\n', 'Ganguly\\n', 'Gangwal\\n', 'Gangwar\\n', 'Ganore\\n', 'Gara\\n', 'Garde\\n', 'Garg\\n', 'Garud\\n', 'Gaur\\n', 'Gautam\\n', 'Gayakwad\\n', 'Gayathri\\n', 'Gehlot\\n', 'Gera\\n', 'Ghose\\n', 'Ghosh\\n', 'Gill\\n', 'Giri\\n', 'Gite\\n', 'Goda\\n', 'Goel\\n', 'Gokhale\\n', 'Gola\\n', 'Gole\\n', 'Golla\\n', 'Gomashe\\n', 'Gond\\n', 'Gopal\\n', 'Goswami\\n', 'Gour\\n', 'Govil\\n', 'Goyal\\n', 'Grewal\\n', 'Grover\\n', 'Gudepu\\n', 'Guduri\\n', 'Guha\\n', 'Gujrati\\n', 'Gulati\\n', 'Gupta\\n', 'Gurjar\\n', 'Gurnani\\n', 'Gurubhaiye\\n', 'Gutti\\n', 'Halder\\n', 'Handa\\n', 'Hanif\\n', 'Hans\\n', 'Hansdah\\n', 'Hanul\\n', 'Haokip\\n', 'Hari\\n', 'Hasija\\n', 'Hasnain\\n', 'Hasni\\n', 'Hayer\\n', 'Hayre\\n', 'Heblikar\\n', 'Hegde\\n', 'Hora\\n', 'Hosur\\n', 'Huque\\n', 'Hussain\\n', 'Inavolu\\n', 'Indora\\n', 'Iqbal\\n', 'Islam\\n', 'Israni\\n', 'Issac\\n', 'Iyengar\\n', 'Iyer\\n', 'Jadhav\\n', 'Jafri\\n', 'Jagaragallu\\n', 'Jaggi\\n', 'Jagtap\\n', 'Jain\\n', 'Jaiswal\\n', 'Jaitley\\n', 'Jajoo\\n', 'Jamloki\\n', 'Jani\\n', 'Jassal\\n', 'Jauhari\\n', 'Jawed\\n', 'Jay\\n', 'Jayaraman\\n', 'Jedhe\\n', 'Jena\\n', 'Jeykumaran\\n', 'Jha\\n', 'Jhaveri\\n', 'Jhindal\\n', 'Jindal\\n', 'Jivani\\n', 'Jodha\\n', 'Johal\\n', 'Johari\\n', 'Jose\\n', 'Joseph\\n', 'Joshi\\n', 'Junankar\\n', 'Juned\\n', 'Juneja\\n', 'Jushantan\\n', 'Kadakia\\n', 'Kade\\n', 'Kairati\\n', 'Kakar\\n', 'Kala\\n', 'Kale\\n', 'Kalita\\n', 'Kalla\\n', 'Kalra\\n', 'Kalsi\\n', 'Kamble\\n', 'Kamdar\\n', 'Kanchan\\n', 'Kanchapu\\n', 'Kancharla\\n', 'Kanchhal\\n', 'Kanda\\n', 'Kannan\\n', 'Kannaujia\\n', 'Kanojia\\n', 'Kansal\\n', 'Kant\\n', 'Kapadia\\n', 'Kapoor\\n', 'Kapur\\n', 'Kar\\n', 'Kara\\n', 'Karan\\n', 'Kari\\n', 'Karkhele\\n', 'Karnik\\n', 'Karpe\\n', 'Kasaudhan\\n', 'Kasera\\n', 'Kashyap\\n', 'Kasniya\\n', 'Kata\\n', 'Katiyar\\n', 'Katta\\n', 'Kaul\\n', 'Kaur\\n', 'Kaushik\\n', 'Kavi\\n', 'Keer\\n', 'Kesarwani\\n', 'Keshari\\n', 'Keshri\\n', 'Keshwani\\n', 'Kewlani\\n', 'Khaliq\\n', 'Khalsa\\n', 'Khan\\n', 'Khandekar\\n', 'Khandelwal\\n', 'Khanna\\n', 'Khare\\n', 'Khatoon\\n', 'Khatri\\n', 'Khatun\\n', 'Khobragade\\n', 'Khokhar\\n', 'Khosla\\n', 'Khurana\\n', 'Kibe\\n', 'Kidwai\\n', 'Kishor\\n', 'Kisshan\\n', 'Kochar\\n', 'Kohli\\n', 'Konda\\n', 'Koppula\\n', 'Kori\\n', 'Korpal\\n', 'Koshy\\n', 'Kota\\n', 'Kothari\\n', 'Kotturu\\n', 'Krish\\n', 'Krishna\\n', 'Krishnamurthy\\n', 'Krishnan\\n', 'Kukreja\\n', 'Kulal\\n', 'Kulkarni\\n', 'Kulsum\\n', 'Kumar\\n', 'Kumari\\n', 'Kumer\\n', 'Kunda\\n', 'Kurian\\n', 'Kuruvilla\\n', 'Kushalappa\\n', 'Kushwaha\\n', 'Kwatra\\n', 'Lad\\n', 'Lakhmani\\n', 'Lal\\n', 'Lala\\n', 'Lalchandani\\n', 'Lall\\n', 'Lalla\\n', 'Lamba\\n', 'Lanka\\n', 'Lata\\n', 'Lavudya\\n', 'Lockwani\\n', 'Loke\\n', 'Loyal\\n', 'Luthra\\n', 'Ma\\n', 'Macharla\\n', 'Machhan\\n', 'Machra\\n', 'Madaan\\n', 'Madala\\n', 'Madan\\n', 'Maddeshiya\\n', 'Maddipatla\\n', 'Madina\\n', 'Magar\\n', 'Magdum\\n', 'Mahajan\\n', 'Mahal\\n', 'Mahalka\\n', 'Mahankali\\n', 'Mahapatra\\n', 'Maharaj\\n', 'Mahato\\n', 'Mahawar\\n', 'Maheshwari\\n', 'Mahmood\\n', 'Mahto\\n', 'Majeed\\n', 'Majhi\\n', 'Majumdar\\n', 'Makavan\\n', 'Malekar\\n', 'Malhotra\\n', 'Malik\\n', 'Mall\\n', 'Mallick\\n', 'Malviya\\n', 'Malwan\\n', 'Mammen\\n', 'Manchanda\\n', 'Manchikanti\\n', 'Mand\\n', 'Manda\\n', 'Mandadi\\n', 'Mandal\\n', 'Mander\\n', 'Mane\\n', 'Mangal\\n', 'Mangat\\n', 'Mangla\\n', 'Mani\\n', 'Manjhi\\n', 'Manju\\n', 'Mann\\n', 'Manna\\n', 'Mannan\\n', 'Manne\\n', 'Masood\\n', 'Mathai\\n', 'Mathur\\n', 'Matthai\\n', 'Maurya\\n', 'Meda\\n', 'Meena\\n', 'Meghwal\\n', 'Mehan\\n', 'Meharda\\n', 'Mehendale\\n', 'Mehra\\n', 'Mehrotra\\n', 'Mehta\\n', 'Meka\\n', 'Memon\\n', 'Menon\\n', 'Merchant\\n', 'Mhaske\\n', 'Middinti\\n', 'Minhas\\n', 'Mishra\\n', 'Misra\\n', 'Mistry\\n', 'Mital\\n', 'Mitra\\n', 'Mittal\\n', 'Mitter\\n', 'Modi\\n', 'Mody\\n', 'Mohan\\n', 'Mohandas\\n', 'Mohanty\\n', 'Molla\\n', 'Mondal\\n', 'Morar\\n', 'More\\n', 'Motwani\\n', 'Mourya\\n', 'Mukherjee\\n', 'Mukhopadhyay\\n', 'Munda\\n', 'Muni\\n', 'Munir\\n', 'Munshi\\n', 'Murlidhar\\n', 'Murmu\\n', 'Murthy\\n', 'Murty\\n', 'Mustafa\\n', 'Mutti\\n', 'Naaz\\n', 'Nadaf\\n', 'Nadhe\\n', 'Nadig\\n', 'Nadkarni\\n', 'Nag\\n', 'Nagar\\n', 'Nagarajan\\n', 'Nagi\\n', 'Nagoria\\n', 'Nagraj\\n', 'Nagy\\n', 'Naidu\\n', 'Naik\\n', 'Nair\\n', 'Nalla\\n', 'Nanda\\n', 'Nandakumar\\n', 'Nandanwar\\n', 'Nanwani\\n', 'Naqvi\\n', 'Narain\\n', 'Narala\\n', 'Narang\\n', 'Narasimhan\\n', 'Narayan\\n', 'Narayanan\\n', 'Narula\\n', 'Nasreen\\n', 'Natarajan\\n', 'Nath\\n', 'Natt\\n', 'Navas\\n', 'Nayak\\n', 'Nayar\\n', 'Nazareth\\n', 'Negi\\n', 'Nichit\\n', 'Nigam\\n', 'Nigan\\n', 'Nischal\\n', 'Nisha\\n', 'Nori\\n', 'Oak\\n', 'Obed\\n', 'Ojha\\n', 'Om\\n', 'Omkar\\n', 'Oommen\\n', 'Oswal\\n', 'Oza\\n', 'Padmanabhan\\n', 'Pai\\n', 'Paighan\\n', 'Pal\\n', 'Palan\\n', 'Palata\\n', 'Palisetti\\n', 'Pall\\n', 'Palla\\n', 'Pallav\\n', 'Panchal\\n', 'Pandey\\n', 'Pandit\\n', 'Pandya\\n', 'Panesar\\n', 'Panghal\\n', 'Pant\\n', 'Paramar\\n', 'Parashar\\n', 'Pareek\\n', 'Parekh\\n', 'Parihar\\n', 'Parikh\\n', 'Parmar\\n', 'Parmer\\n', 'Parsa\\n', 'Parul\\n', 'Parween\\n', 'Pasupuleti\\n', 'Paswan\\n', 'Patal\\n', 'Patel\\n', 'Pathak\\n', 'Pathan\\n', 'Patil\\n', 'Patla\\n', 'Patra\\n', 'Pattnaik\\n', 'Pau\\n', 'Paul\\n', 'Pawar\\n', 'Pereddy\\n', 'Peri\\n', 'Pillai\\n', 'Pillay\\n', 'Pingle\\n', 'Poddar\\n', 'Pokhriyal\\n', 'Porwal\\n', 'Prabhakar\\n', 'Prabhu\\n', 'Pradhan\\n', 'Prajapati\\n', 'Prakash\\n', 'Prasad\\n', 'Prasath\\n', 'Prashad\\n', 'Praveenchand\\n', 'Pravesh\\n', 'Preetham\\n', 'Priya\\n', 'Priyadarshi\\n', 'Priyadarshini\\n', 'Pundir\\n', 'Puri\\n', 'Purkayastha\\n', 'Purohit\\n', 'Purwar\\n', 'Putta\\n', 'Quadiri\\n', 'Quraishi\\n', 'Radhakrishnan\\n', 'Raghavan\\n', 'Rai\\n', 'Raj\\n', 'Raja\\n', 'Rajagopal\\n', 'Rajagopalan\\n', 'Rajak\\n', 'Rajan\\n', 'Rajendra\\n', 'Rajesh\\n', 'Rajput\\n', 'Raju\\n', 'Rakhecha\\n', 'Ram\\n', 'Rama\\n', 'Ramachandran\\n', 'Ramakrishnan\\n', 'Raman\\n', 'Ramanathan\\n', 'Ramaswamy\\n', 'Ramesh\\n', 'Rana\\n', 'Randhawa\\n', 'Ranganathan\\n', 'Rani\\n', 'Ranjan\\n', 'Rao\\n', 'Rasheed\\n', 'Rastogi\\n', 'Rathod\\n', 'Rathore\\n', 'Rathour\\n', 'Ratta\\n', 'Rattan\\n', 'Ratti\\n', 'Rau\\n', 'Rauniyar\\n', 'Rausa\\n', 'Raut\\n', 'Raval\\n', 'Ravel\\n', 'Ravi\\n', 'Rawat\\n', 'Rawlani\\n', 'Ray\\n', 'Raykar\\n', 'Raza\\n', 'Reddy\\n', 'Rege\\n', 'Rehman\\n', 'Rishiraj\\n', 'Ritikesh\\n', 'Rizvi\\n', 'Rizwan\\n', 'Roshan\\n', 'Rout\\n', 'Roy\\n', 'Rungta\\n', 'Ruqaiya\\n', 'Sabharwal\\n', 'Sachan\\n', 'Sachar\\n', 'Sachdev\\n', 'Sachdeva\\n', 'Sagar\\n', 'Sah\\n', 'Saha\\n', 'Sahai\\n', 'Sahni\\n', 'Sahota\\n', 'Sahu\\n', 'Sain\\n', 'Saini\\n', 'Saluja\\n', 'Salvi\\n', 'Sama\\n', 'Samaddar\\n', 'Samdharshni\\n', 'Sami\\n', 'Sampath\\n', 'Samra\\n', 'Sandal\\n', 'Sandhu\\n', 'Sandilya\\n', 'Sane\\n', 'Sangha\\n', 'Sanghvi\\n', 'Sani\\n', 'Sankar\\n', 'Sankaran\\n', 'Sankary\\n', 'Sant\\n', 'Sanwal\\n', 'Saraf\\n', 'Saran\\n', 'Saraswat\\n', 'Sarath\\n', 'Sarawagi\\n', 'Sardar\\n', 'Sareen\\n', 'Sarin\\n', 'Sarkar\\n', 'Sarma\\n', 'Sarna\\n', 'Sarnobat\\n', 'Sarraf\\n', 'Sasanka\\n', 'Sasidharan\\n', 'Sastry\\n', 'Sathe\\n', 'Savant\\n', 'Sawhney\\n', 'Sawlani\\n', 'Saxena\\n', 'Sehgal\\n', 'Sekh\\n', 'Sekhar\\n', 'Sekhon\\n', 'Selvaraj\\n', 'Sem\\n', 'Sen\\n', 'Sengar\\n', 'Sengupta\\n', 'Seshadri\\n', 'Seth\\n', 'Sethi\\n', 'Setty\\n', 'Sha\\n', 'Shah\\n', 'Shahi\\n', 'Shahid\\n', 'Shaik\\n', 'Shaikh\\n', 'Shaji\\n', 'Shan\\n', 'Shandilya\\n', 'Shankar\\n', 'Shankdhar\\n', 'Shanker\\n', 'Sharaf\\n', 'Sharma\\n', 'Shekhar\\n', 'Shenoy\\n', 'Shere\\n', 'Sheth\\n', 'Shetty\\n', 'Shinde\\n', 'Shingh\\n', 'Shiromani\\n', 'Shivagauri\\n', 'Shivastava\\n', 'Shoaib\\n', 'Shokeen\\n', 'Shrivas\\n', 'Shrivastav\\n', 'Shrivastava\\n', 'Shroff\\n', 'Shukla\\n', 'Sibal\\n', 'Siddiqui\\n', 'Sidhu\\n', 'Sikarwar\\n', 'Singam\\n', 'Singh\\n', 'Singhal\\n', 'Singhania\\n', 'Sinh\\n', 'Sinha\\n', 'Siraj\\n', 'Sirohi\\n', 'Sitaram\\n', 'Sivan\\n', 'Sodhi\\n', 'Solanki\\n', 'Som\\n', 'Soman\\n', 'Sonawane\\n', 'Sondhi\\n', 'Soni\\n', 'Sonkar\\n', 'Sonker\\n', 'Sonwani\\n', 'Sood\\n', 'Souza\\n', 'Sridhar\\n', 'Srinivas\\n', 'Srinivasan\\n', 'Srivastav\\n', 'Srivastava\\n', 'Subbapati\\n', 'Subramaniam\\n', 'Subramanian\\n', 'Suchi\\n', 'Sugathan\\n', 'Sule\\n', 'Suman\\n', 'Sundar\\n', 'Sundaram\\n', 'Sunder\\n', 'Sur\\n', 'Sura\\n', 'Surabhi\\n', 'Suresh\\n', 'Suri\\n', 'Sutariya\\n', 'Swain\\n', 'Swaminathan\\n', 'Swamy\\n', 'Tailor\\n', 'Tak\\n', 'Talwar\\n', 'Tandon\\n', 'Taneja\\n', 'Tangirala\\n', 'Tank\\n', 'Tanu\\n', 'Tara\\n', 'Tata\\n', 'Tayde\\n', 'Teja\\n', 'Tejaswini\\n', 'Tekchandani\\n', 'Tella\\n', 'Tewari\\n', 'Tewary\\n', 'Thaker\\n', 'Thakkar\\n', 'Thakor\\n', 'Thakur\\n', 'Thaman\\n', 'Thawani\\n', 'Theratipally\\n', 'Tibrewal\\n', 'Tidke\\n', 'Tiwari\\n', 'Tomar\\n', 'Toor\\n', 'Tripathi\\n', 'Trivedi\\n', 'Tulshidas\\n', 'Tyagi\\n', 'Umar\\n', 'Unnikrishnan\\n', 'Upadhyay\\n', 'Uppal\\n', 'Upreti\\n', 'Vaidya\\n', 'Vaish\\n', 'Vaishnavi\\n', 'Vala\\n', 'Varghese\\n', 'Varkey\\n', 'Varma\\n', 'Varshney\\n', 'Varty\\n', 'Varughese\\n', 'Vasa\\n', 'Vasav\\n', 'Vashisth\\n', 'Vasistha\\n', 'Veerepalli\\n', 'Venkataraman\\n', 'Venkatesh\\n', 'Venkateshwaran\\n', 'Verma\\n', 'Vig\\n', 'Vikram\\n', 'Vilas\\n', 'Virani\\n', 'Virk\\n', 'Vishal\\n', 'Vishwakarma\\n', 'Viswanathan\\n', 'Vohra\\n', 'Vora\\n', 'Vyas\\n', 'Wable\\n', 'Wadhawan\\n', 'Wadhwa\\n', 'Wagh\\n', 'Wagle\\n', 'Wali\\n', 'Walia\\n', 'Walla\\n', 'Wanve\\n', 'Warrior\\n', 'Warsi\\n', 'Waseem\\n', 'Wasif\\n', 'Wason\\n', 'Wathore\\n', 'Waybhase\\n', 'Waykos\\n', 'Yadav\\n', 'Yaddanapudi\\n', 'Yamala\\n', 'Yogi\\n', 'Yohannan\\n', 'Zacharia\\n', 'Zachariah\\n', 'Zaidi\\n', 'Zehra\\n', 'Zope']\n"
          ]
        }
      ],
      "source": [
        "with open('last_name.txt', 'r') as l:\n",
        "    last_name = l.readlines()\n",
        "print(last_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2dVXQuzLxSa",
        "outputId": "c1f3e83b-7df6-424e-b918-4c0d665a445e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2195, 1038)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "len(first_name),len(last_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Beq40xoEMCo3"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from random import choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qJcWXh5ZMPlz",
        "outputId": "3b6f5c45-e92d-406f-b2ce-15d71ed1305e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Divya\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "choice(first_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta4wS-yiIKkK",
        "outputId": "a965d8e9-ffe4-45f8-bf4f-2a2e16a9a139"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vivek']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "'vivek'.split(' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "smw4im47L3-I"
      },
      "outputs": [],
      "source": [
        "names = []\n",
        "for i in range(4000):\n",
        "    t = random.randint(0,3)\n",
        "    if t==1:\n",
        "        name  = choice(first_name).strip()\n",
        "    elif t==2:\n",
        "        name = choice(last_name).strip()\n",
        "    else:\n",
        "        name = choice(first_name).strip()+' '+choice(last_name).strip()\n",
        "    names.append(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UykMLP6YMhqY",
        "outputId": "e130114a-2719-4d67-859c-b49ae9f252d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Datta', 'Kumari', 'Yakub Manju', 'Hammaad Parihar', 'Huque', 'Tewary', 'Suraj Rajendra', 'Tavish Sura', 'Elili', 'Deep', 'Tanishta Preetham', 'Shinde', 'Bhavani Meda', 'Anjoo Dara', 'Saharsh Sodhi', 'Choudhary', 'Shahi', 'Mrinal Narula', 'Shyam Paramar', 'Aeman']\n"
          ]
        }
      ],
      "source": [
        "print(names[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "x9y7JdcsMi5S"
      },
      "outputs": [],
      "source": [
        "templates = [\n",
        "    # 🧍‍♂️ Just name\n",
        "    \"{full_name}\",\n",
        "    \"{full_name}.\",\n",
        "    \"Name: {full_name}\",\n",
        "\n",
        "    \"{full_name} ⋄ Emails: {email1}, {email2}, {email3} ⋄ LinkedIn: {linkedin1}, {linkedin2} ⋄ Blogs: {blog1}, {blog2} ⋄ Portfolio: {portfolio}\",\n",
        "    \"Resume of {full_name} | Contact: {email1} | LinkedIn: {linkedin1} | Portfolio: {portfolio} | Blog: {blog1}\",\n",
        "    \"{full_name} graduated B.Tech from {college_name} in {grad_year} with CGPA {cgpa}.\",\n",
        "    \"{full_name} is proficient in {skill_list}, {skill_list2}, and {skill_list3}.\",\n",
        "    \"Project “{project_name}” ({project_year})—built by {full_name} using {skill_list} and {skill_list2}.\",\n",
        "    \"{full_name} worked at {company_name} as a {role} from {start_month} {start_year} to {end_month} {end_year}.\",\n",
        "    \"{full_name} secured {rank} in {contest_name} and earned a {certificate} certificate.\",\n",
        "    \"Handles → Codechef: {handle_cc} | CodeForces: {handle_cf} | LeetCode: {handle_lc} (by {full_name})\",\n",
        "    \"Meet {full_name}, a full‑stack dev skilled in {skill_list}. Contact: {email1}, Portfolio: {portfolio}.\",\n",
        "    \"Mr. {full_name} uses {tool1}, {tool2}, {tool3} daily at {company_name}.\",\n",
        "    \"Internship: {full_name} at {company_name} (Data Science team, {start_month} {start_year}).\",\n",
        "    \"Blog → {blog1}, {blog2}, LinkedIn → {linkedin1}, {linkedin2}. Author: {full_name}.\",\n",
        "    \"Summary: {full_name} from {location}, skilled in {skill_list}, projects include {project_name}.\",\n",
        "    \"Contact Info: Emails: {email1}, {email2}; LinkedIns: {linkedin1}, {linkedin2}; Portfolio: {portfolio}.\",\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "4PwAXMsbslAZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "years = [str(y) for y in range(2018, 2025)]\n",
        "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
        "\n",
        "# Expanded colleges list (50 items)\n",
        "colleges = [\n",
        "    \"IIT Bombay\", \"NIT Trichy\", \"BITS Pilani\", \"IIIT Hyderabad\", \"IIT Delhi\",\n",
        "    'PUBLIC SCHOOL','CBSE','Central board of secondary education','aktu',\n",
        "    \"IIT Madras\", \"IIT Kanpur\", \"NIT Surathkal\", \"DTU Delhi\", \"NSIT Delhi\",\n",
        "    \"IIT Kharagpur\", \"IIT Roorkee\", \"IIT Guwahati\", \"IIT Bhubaneswar\", \"IIT Gandhinagar\",\n",
        "    \"NIT Warangal\", \"NIT Calicut\", \"NIT Rourkela\", \"NIT Jaipur\", \"NIT Karnataka\",\n",
        "    \"VIT Vellore\", \"SRM University\", \"Manipal Institute\", \"Thapar University\", \"BHU Varanasi\",\n",
        "    \"University of Delhi\", \"University of Mumbai\", \"University of Calcutta\", \"University of Madras\",\n",
        "    \"Anna University\", \"Jadavpur University\", \"Pune University\", \"Amity University\", \"LPU Punjab\",\n",
        "    \"Symbiosis Pune\", \"Christ University\", \"St. Xavier's Mumbai\", \"Fergusson College\", \"Presidency College\",\n",
        "    \"Harvard University\", \"MIT\", \"Stanford University\", \"UC Berkeley\", \"Cambridge University\", \"Oxford University\",\n",
        "    \"ETH Zurich\", \"National University Singapore\", \"University of Toronto\", \"University of Melbourne\", \"University of Tokyo\"\n",
        "]\n",
        "\n",
        "# Expanded skills list (100 items)\n",
        "skills = [\n",
        "    'C++','C','Java','DSA','algorithm','Leadership','Languages C++'\n",
        "    \"Python\", \"Machine Learning\", \"Django\", \"React\", \"JavaScript\", \"Data Structures\", \"AWS\", \"Docker\", \"Kubernetes\", \"TensorFlow\",\n",
        "    \"PyTorch\", \"Flask\", \"Node.js\", \"MongoDB\", \"SQL\", \"Java\", \"C++\", \"Git\", \"Jenkins\", \"Ansible\",'C++','C','JAVA'\n",
        "    \"Terraform\", \"Prometheus\", \"Grafana\", \"Splunk\", \"Kafka\", \"Spark\", \"Hadoop\", \"Pandas\", \"NumPy\", \"SciPy\",\n",
        "    \"Matplotlib\", \"Seaborn\", \"OpenCV\", \"NLTK\", \"spaCy\", \"HuggingFace\", \"FastAPI\", \"GraphQL\", \"REST API\", \"gRPC\",\n",
        "    \"Microservices\", \"CI/CD\", \"Linux\", \"Bash\", \"PowerShell\", \"Azure\", \"GCP\", \"Heroku\", \"Firebase\", \"PostgreSQL\",\n",
        "    \"MySQL\", \"SQLite\", \"Redis\", \"Elasticsearch\", \"Neo4j\", \"Cassandra\", \"RabbitMQ\", \"Celery\", \"Selenium\", \"Pytest\",\n",
        "    \"JUnit\", \"Mockito\", \"Jira\", \"Confluence\", \"Trello\", \"Agile\", \"Scrum\", \"Kanban\", \"Data Analysis\", \"Data Visualization\",\n",
        "    \"Tableau\", \"Power BI\", \"Excel\", \"Statistics\", \"Probability\", \"Linear Algebra\", \"Calculus\", \"Deep Learning\", \"NLP\", \"Computer Vision\",\n",
        "    \"Reinforcement Learning\", \"Big Data\", \"ETL\", \"Airflow\", \"MLflow\", \"DVC\", \"TypeScript\", \"Angular\", \"Vue.js\", \"Svelte\",\n",
        "    \"Next.js\", \"Nuxt.js\", \"Webpack\", \"Babel\", \"ESLint\", \"Prettier\", \"Jest\", \"Cypress\", \"Storybook\", \"Figma\"\n",
        "]\n",
        "\n",
        "# Expanded projects list (50 items)\n",
        "projects = [\n",
        "    \"ResumeParser\", \"CalorieTracker\", \"E-Commerce Platform\", \"Chat Application\", \"Stock Market Predictor\",\n",
        "    \"Facial Recognition System\", \"Blockchain Implementation\", \"Automated Testing Framework\", \"Recommendation Engine\", \"IoT Home Automation\",\n",
        "    \"Voice Assistant\", \"Sentiment Analysis Tool\", \"Fraud Detection System\", \"Inventory Management\", \"Hospital Management System\",\n",
        "    \"College ERP System\", \"Parking Slot Finder\", \"Traffic Management System\", \"Weather Forecasting App\", \"Crop Disease Detection\",\n",
        "    \"Fitness Tracker\", \"Food Delivery App\", \"Online Examination System\", \"Blog Platform\", \"Social Media Analytics\",\n",
        "    \"Credit Score Predictor\", \"HR Management System\", \"Expense Tracker\", \"Job Portal\", \"Real Estate Price Predictor\",\n",
        "    \"Music Recommendation System\", \"Video Conferencing App\", \"Document Scanner\", \"OCR System\", \"Handwriting Recognition\",\n",
        "    \"Augmented Reality App\", \"Virtual Reality Tour\", \"3D Model Viewer\", \"Drone Controller\", \"Autonomous Vehicle Simulation\",\n",
        "    \"Smart Mirror\", \"Gesture Control System\", \"Speech Emotion Recognition\", \"Sign Language Translator\", \"Plagiarism Checker\",\n",
        "    \"Code Compiler\", \"Online IDE\", \"Password Manager\", \"VPN Service\", \"File Encryption System\"\n",
        "]\n",
        "\n",
        "# Expanded roles list (50 items)\n",
        "roles = [\n",
        "    \"Software Engineer\", \"Data Analyst\", \"Machine Learning Engineer\", \"DevOps Engineer\", \"Full Stack Developer\",\n",
        "    \"Backend Developer\", \"Frontend Developer\", \"Data Scientist\", \"Product Manager\", \"Cloud Architect\",\n",
        "    \"Systems Engineer\", \"Network Engineer\", \"Security Engineer\", \"QA Engineer\", \"Test Automation Engineer\",\n",
        "    \"Embedded Systems Engineer\", \"Firmware Engineer\", \"Game Developer\", \"Mobile Developer\", \"iOS Developer\",\n",
        "    \"Android Developer\", \"UX Designer\", \"UI Designer\", \"Graphic Designer\", \"Technical Writer\",\n",
        "    \"Database Administrator\", \"Data Engineer\", \"BI Developer\", \"ETL Developer\", \"Solutions Architect\",\n",
        "    \"Site Reliability Engineer\", \"Release Engineer\", \"Build Engineer\", \"Performance Engineer\", \"Security Analyst\",\n",
        "    \"Penetration Tester\", \"Ethical Hacker\", \"Scrum Master\", \"Agile Coach\", \"Project Manager\",\n",
        "    \"Engineering Manager\", \"CTO\", \"Technical Lead\", \"Team Lead\", \"Principal Engineer\",\n",
        "    \"Research Scientist\", \"AI Researcher\", \"ML Researcher\", \"Computer Vision Engineer\", \"NLP Engineer\"\n",
        "]\n",
        "\n",
        "# Other expanded lists\n",
        "companies = [\n",
        "    \"Google\", \"Amazon\", \"Flipkart\", \"Microsoft\", \"Adobe\", \"Goldman Sachs\", \"JPMorgan Chase\", \"TCS\", \"Infosys\", \"Wipro\",\n",
        "    \"Accenture\", \"IBM\", \"Oracle\", \"Intel\", \"NVIDIA\", \"Qualcomm\", \"Samsung\", \"Apple\", \"Tesla\", \"SpaceX\",\n",
        "    \"Netflix\", \"Meta\", \"Twitter\", \"LinkedIn\", \"Uber\", \"Ola\", \"Zomato\", \"Swiggy\", \"Paytm\", \"PhonePe\",\n",
        "    \"Razorpay\", \"Byju's\", \"Unacademy\", \"UpGrad\", \"Coursera\", \"Udemy\", \"Hotstar\", \"Zee5\", \"Sony\", \"Viacom\",\n",
        "    \"Reliance\", \"Tata\", \"Adani\", \"Mahindra\", \"HDFC\", \"ICICI\", \"Kotak\", \"Axis\", \"SBI\", \"Yes Bank\"\n",
        "]\n",
        "\n",
        "contests = [\n",
        "    \"Smart India Hackathon\", \"Meta Hacker Cup\", \"Google Code Jam\", \"ACM ICPC\", \"Facebook Hacker Cup\",\n",
        "    \"CodeChef SnackDown\", \"Hash Code\", \"Kick Start\", \"LeetCode Biweekly Contest\", \"Topcoder Open\",\n",
        "    \"AtCoder Grand Contest\", \"Codeforces Global Round\", \"HackerRank Challenge\", \"Kaggle Competition\", \"DataHack\",\n",
        "    \"MathWorks Cody\", \"IEEE Xtreme\", \"IARCS Programming Contest\", \"ZCO\", \"INOI\",\n",
        "    \"Google Summer of Code\", \"Outreachy\", \"MLH Fellowship\", \"Hack the North\", \"HackMIT\",\n",
        "    \"PennApps\", \"HackHarvard\", \"TechGig Code Gladiators\", \"Dare2Compete\", \"Unstop\",\n",
        "    'Codeforces','CodeChef','LeetCode','Codechef','Leetcode',\n",
        "    \"AngelHack\", \"Devfolio Hackathon\", \"ETHGlobal\", \"GitHub Hackathon\", \"Microsoft Imagine Cup\",\n",
        "    \"IBM Call for Code\", \"AWS Hackathon\", \"Google Solution Challenge\", \"JP Morgan Code for Good\", \"American Express Hackathon\"\n",
        "]\n",
        "\n",
        "certificates = [\n",
        "    \"Coursera Machine Learning\", \"Codechef SQL\", \"AWS Certified Solutions Architect\", \"Google Data Analytics Professional\",\n",
        "    \"Microsoft Certified Azure Fundamentals\", \"Deep Learning Specialization\", \"TensorFlow Developer Certificate\", \"Oracle Certified Java Programmer\",\n",
        "    \"Certified Kubernetes Administrator\", \"Scrum Master Certification\", \"Google Cloud Professional\", \"Azure AI Engineer\", \"AWS DevOps Engineer\",\n",
        "    \"Red Hat Certified Engineer\", \"Cisco Certified Network Associate\", \"Certified Ethical Hacker\", \"CompTIA Security+\", \"PMI Agile Certified Practitioner\",\n",
        "    \"ISTQB Certified Tester\", \"Salesforce Certified Developer\", \"Tableau Desktop Specialist\", \"Data Science Council of America\", \"Cloudera Certified Associate\",\n",
        "    \"Hortonworks Hadoop Certification\", \"Google IT Support Professional\", \"IBM Data Science Professional\", \"Microsoft Certified Data Scientist\", \"SAS Certified Specialist\",\n",
        "    \"Alteryx Designer Core\", \"Qlik Sense Business Analyst\", \"Snowflake SnowPro Core\", \"Databricks Certified Associate\", \"MongoDB Certified Developer\",\n",
        "    \"Neo4j Certified Professional\", \"Elastic Certified Engineer\", \"Confluent Certified Developer\", \"HashiCorp Certified Terraform Associate\", \"Linux Foundation Certified Engineer\",\n",
        "    \"Python Institute PCAP\", \"Microsoft Python Certification\", \"Oracle Database SQL Certified\", \"C++ Institute CPA\", \"Java Oracle Certified Associate\"\n",
        "]\n",
        "\n",
        "tools = [\n",
        "    \"Git\", \"Docker\", \"AWS\", \"Kubernetes\", \"Jenkins\", \"Ansible\", \"Terraform\", \"Prometheus\", \"Grafana\", \"Splunk\",\n",
        "    \"Kafka\", \"Spark\", \"Hadoop\", \"Airflow\", \"MLflow\", \"DVC\", \"Jira\", \"Confluence\", \"Trello\", \"Figma\",\n",
        "    \"Adobe XD\", \"Sketch\", \"Zeplin\", \"Postman\", \"Swagger\", \"Insomnia\", \"SoapUI\", \"JMeter\", \"Selenium\", \"Appium\",\n",
        "    \"Cypress\", \"JUnit\", \"Mockito\", \"TestNG\", \"Cucumber\", \"Robot Framework\", \"SonarQube\", \"Checkmarx\", \"Burp Suite\", \"Wireshark\",\n",
        "    \"Nmap\", \"Metasploit\", \"Kali Linux\", \"VirtualBox\", \"VMware\", \"Docker Compose\", \"Helm\", \"Istio\", \"Knative\", \"Kubeflow\"\n",
        "]\n",
        "\n",
        "locations = [\n",
        "    \"Mumbai\", \"Delhi\", \"Bangalore\", \"Hyderabad\", \"Chennai\", \"Pune\", \"Kolkata\", \"Ahmedabad\", \"Jaipur\", \"Lucknow\",\n",
        "    \"Surat\", \"Kanpur\", \"Nagpur\", \"Visakhapatnam\", \"Indore\", \"Thane\", \"Bhopal\", \"Patna\", \"Vadodara\", \"Ghaziabad\",\n",
        "    \"Ludhiana\", \"Coimbatore\", \"Agra\", \"Nashik\", \"Ranchi\", \"Faridabad\", \"Meerut\", \"Rajkot\", \"Varanasi\", \"Srinagar\",\n",
        "    \"Aurangabad\", \"Dhanbad\", \"Amritsar\", \"Allahabad\", \"Howrah\", \"Gwalior\", \"Jodhpur\", \"Raipur\", \"Kota\", \"Chandigarh\",\n",
        "    \"New York\", \"London\", \"Tokyo\", \"Sydney\", \"Singapore\", \"Dubai\", \"Berlin\", \"Paris\", \"Toronto\", \"San Francisco\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "dcr1B5nVs_oz"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_email(name):\n",
        "    \"\"\"Return a random email for a given full name.\"\"\"\n",
        "    first, last = name.split()\n",
        "    patterns = [\n",
        "        f\"{first[0].lower()}{last.lower()}@gmail.com\",\n",
        "        f\"{first.lower()}_{random.randint(10,99)}@outlook.com\",\n",
        "        f\"{last.lower()}@example.com\"\n",
        "    ]\n",
        "    return random.choice(patterns)\n",
        "\n",
        "def generate_email(name):\n",
        "    \"\"\"Return a random LinkedIn profile URL for a given full name.\"\"\"\n",
        "    temp = name.split()\n",
        "    first = temp[0]\n",
        "    last = temp[-1]\n",
        "    patterns = [\n",
        "        f\"https://linkedin.com/in/{first.lower()}-{last.lower()}\",\n",
        "        f\"https://linkedin.com/in/{first[0].lower()}{last.lower()}\",\n",
        "        f\"https://linkedin.com/in/{first.lower()}{random.choice(['dev','eng','ai','data'])}\"\n",
        "    ]\n",
        "    return random.choice(patterns)\n",
        "\n",
        "def generate_blog_url(name):\n",
        "    \"\"\"Return a random blog URL for a given full name.\"\"\"\n",
        "    temp = name.split()\n",
        "    first = temp[0]\n",
        "    last = temp[-1]\n",
        "    patterns = [\n",
        "        f\"https://medium.com/{first.lower()}-{last.lower()}\",\n",
        "        f\"https://dev.to/{first.lower()}_{last.lower()}\",\n",
        "        f\"https://{first.lower()}.substack.com\"\n",
        "    ]\n",
        "    return random.choice(patterns)\n",
        "\n",
        "def generate_portfolio_url(name):\n",
        "    \"\"\"Return a random portfolio URL for a given full name.\"\"\"\n",
        "    temp = name.split()\n",
        "    first = temp[0]\n",
        "    last = temp[-1]\n",
        "    patterns = [\n",
        "        f\"https://{first.lower()}.portfolio.dev\",\n",
        "        f\"https://{last.lower()}.tech\",\n",
        "        f\"https://{first.lower()}{last.lower()}.me\"\n",
        "    ]\n",
        "    return random.choice(patterns)\n",
        "\n",
        "def generate_codechef_handle(name):\n",
        "    \"\"\"Return a random CodeChef handle for a given full name.\"\"\"\n",
        "    first, last = name.split()\n",
        "    return f\"{first.lower()}{last.lower()}{random.randint(1,999)}\"\n",
        "\n",
        "def generate_codeforces_handle(name):\n",
        "    \"\"\"Return a random Codeforces handle for a given full name.\"\"\"\n",
        "    temp = name.split()\n",
        "    first = temp[0]\n",
        "    last = temp[-1]\n",
        "    return f\"{first.lower()}_{last.lower()}{random.randint(1,999)}\"\n",
        "\n",
        "def generate_leetcode_handle(name):\n",
        "    \"\"\"Return a random LeetCode handle for a given full name.\"\"\"\n",
        "    temp = name.split()\n",
        "    first = temp[0]\n",
        "    last = temp[-1]\n",
        "    return f\"{first.lower()}{last.lower()}{random.randint(1,500)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXHMiO9eNHms",
        "outputId": "487822a9-b1a4-49ad-bffb-72fde51d972c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  myfolder.zip\n",
            "   creating: person_only_model/\n",
            "   creating: person_only_model/lemmatizer/\n",
            "   creating: person_only_model/lemmatizer/lookups/\n",
            "  inflating: person_only_model/lemmatizer/lookups/lookups.bin  \n",
            "   creating: person_only_model/vocab/\n",
            " extracting: person_only_model/vocab/key2row  \n",
            "  inflating: person_only_model/vocab/strings.json  \n",
            " extracting: person_only_model/vocab/vectors.cfg  \n",
            "  inflating: person_only_model/vocab/vectors  \n",
            "  inflating: person_only_model/vocab/lookups.bin  \n",
            "  inflating: person_only_model/config.cfg  \n",
            "   creating: person_only_model/tok2vec/\n",
            " extracting: person_only_model/tok2vec/cfg  \n",
            "  inflating: person_only_model/tok2vec/model  \n",
            "  inflating: person_only_model/tokenizer  \n",
            "   creating: person_only_model/ner/\n",
            "  inflating: person_only_model/ner/moves  \n",
            "  inflating: person_only_model/ner/cfg  \n",
            "  inflating: person_only_model/ner/model  \n",
            "   creating: person_only_model/senter/\n",
            " extracting: person_only_model/senter/cfg  \n",
            "  inflating: person_only_model/senter/model  \n",
            "   creating: person_only_model/tagger/\n",
            "  inflating: person_only_model/tagger/cfg  \n",
            "  inflating: person_only_model/tagger/model  \n",
            "   creating: person_only_model/attribute_ruler/\n",
            "  inflating: person_only_model/attribute_ruler/patterns  \n",
            "   creating: person_only_model/parser/\n",
            "  inflating: person_only_model/parser/moves  \n",
            "  inflating: person_only_model/parser/cfg  \n",
            "  inflating: person_only_model/parser/model  \n",
            "  inflating: person_only_model/meta.json  \n"
          ]
        }
      ],
      "source": [
        "! unzip myfolder.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "1_SgYpG6M10m"
      },
      "outputs": [],
      "source": [
        "TRAIN_DATA = []\n",
        "for _ in range(2000):\n",
        "    first, last = random.choice(names).split()[0], random.choice(names).split()[-1]\n",
        "    full_name      = f\"{first} {last}\"\n",
        "    email1         = generate_email(full_name)\n",
        "    email2         = generate_email(full_name)\n",
        "    email3         = generate_email(full_name)\n",
        "    linkedin1      = generate_email(full_name)\n",
        "    linkedin2      = generate_email(full_name)\n",
        "    blog1          = generate_blog_url(full_name)\n",
        "    blog2          = generate_blog_url(full_name)\n",
        "    portfolio      = generate_portfolio_url(full_name)\n",
        "    college_name   = random.choice(colleges)\n",
        "    grad_year      = random.choice(years)\n",
        "    cgpa           = f\"{random.uniform(7.0, 9.9):.2f}\"\n",
        "    skill_list     = random.choice(skills)\n",
        "    skill_list2    = random.choice(skills)\n",
        "    skill_list3    = random.choice(skills)\n",
        "    project_name   = random.choice(projects)\n",
        "    project_year   = random.choice(years)\n",
        "    company_name   = random.choice(companies)\n",
        "    role           = random.choice(roles)\n",
        "    start_month    = random.choice(months)\n",
        "    start_year     = random.choice(years)\n",
        "    end_month      = random.choice(months)\n",
        "    end_year       = random.choice(years)\n",
        "    rank           = random.choice([\"1st\", \"2nd\", \"3rd\", \"Top 10\"])\n",
        "    contest_name   = random.choice(contests)\n",
        "    certificate    = random.choice(certificates)\n",
        "    handle_cc      = generate_codechef_handle(full_name)\n",
        "    handle_cf      = generate_codeforces_handle(full_name)\n",
        "    handle_lc      = generate_leetcode_handle(full_name)\n",
        "    tool1          = random.choice(tools)\n",
        "    tool2          = random.choice(tools)\n",
        "    tool3          = random.choice(tools)\n",
        "    location       = random.choice(locations)\n",
        "\n",
        "    template  = random.choice(templates)\n",
        "    sentence  = template.format(**locals())\n",
        "    start     = sentence.find(full_name)\n",
        "    end       = start + len(full_name)\n",
        "    TRAIN_DATA.append((sentence, {\"entities\": [(start, end, \"PERSON\")]}))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a7DUHpzNRSV",
        "outputId": "d35eefcd-4a2e-4799-ae0b-d9890d2e9df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Samardh Rai is proficient in ESLint, Leadership, and Confluence.', {'entities': [(0, 11, 'PERSON')]})\n",
            "('Meet Bhaskor Ashraf, a full‑stack dev skilled in Matplotlib. Contact: https://linkedin.com/in/bhaskor-ashraf, Portfolio: https://ashraf.tech.', {'entities': [(5, 19, 'PERSON')]})\n",
            "('Jayaraman Ratnesh ⋄ Emails: https://linkedin.com/in/jratnesh, https://linkedin.com/in/jayaramandata, https://linkedin.com/in/jayaraman-ratnesh ⋄ LinkedIn: https://linkedin.com/in/jayaraman-ratnesh, https://linkedin.com/in/jayaramaneng ⋄ Blogs: https://dev.to/jayaraman_ratnesh, https://medium.com/jayaraman-ratnesh ⋄ Portfolio: https://ratnesh.tech', {'entities': [(0, 17, 'PERSON')]})\n",
            "('Summary: Arasi Azmi from Raipur, skilled in Firebase, projects include Recommendation Engine.', {'entities': [(9, 19, 'PERSON')]})\n",
            "('Internship: Bhatnagar Sarath at Intel (Data Science team, Jul 2020).', {'entities': [(12, 28, 'PERSON')]})\n",
            "('Astitva Aviral secured Top 10 in Codeforces and earned a Python Institute PCAP certificate.', {'entities': [(0, 14, 'PERSON')]})\n",
            "('Karan Kade secured 1st in CodeChef and earned a Microsoft Certified Data Scientist certificate.', {'entities': [(0, 10, 'PERSON')]})\n",
            "('Tella Ojha graduated B.Tech from LPU Punjab in 2023 with CGPA 7.31.', {'entities': [(0, 10, 'PERSON')]})\n",
            "('Name: Vangara Jha', {'entities': [(6, 17, 'PERSON')]})\n",
            "('Internship: Jignesh Nag at Twitter (Data Science team, Nov 2019).', {'entities': [(12, 23, 'PERSON')]})\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    print(TRAIN_DATA[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S_5NbStOZFL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "COiBH_C2Nf3g"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the pretrained small English model\n",
        "# spacy.require_gpu() uncomment  if gpu is available\n",
        "nlp = spacy.load(\"person_only_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "T78dk7kBOWUP"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Get the NER component\n",
        "ner = nlp.get_pipe(\"ner\")\n",
        "\n",
        "# Add the \"PERSON\" label if it's not already present\n",
        "if \"PERSON\" not in ner.labels:\n",
        "    ner.add_label(\"PERSON\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "OL-7zyGIRBc_"
      },
      "outputs": [],
      "source": [
        "# !pip install -U spacy[cuda12x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka5AnwN0Q9lS",
        "outputId": "49cc96d4-5546-4421-f040-07de2b1a580a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy using GPU: False\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Check if spaCy is using GPU\n",
        "print(\"spaCy using GPU:\", spacy.prefer_gpu())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "_Po4CU4JVp6C"
      },
      "outputs": [],
      "source": [
        "from spacy.training.example import Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbCy_RVaU93W",
        "outputId": "9705ffc7-36d6-4b61-e464-a17e45d4febb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/rita...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/balo...\" with entities \"[(-1, 11, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/beli...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/shre...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/apar...\" with entities \"[(-1, 14, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/jiva...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/vird...\" with entities \"[(-1, 7, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/saha...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/shab...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/gude...\" with entities \"[(-1, 11, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/jjan...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/maso...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/bdhi...\" with entities \"[(-1, 14, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/mahi...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/rach...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/dcha...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/sahd...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/vmah...\" with entities \"[(-1, 17, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/mahi...\" with entities \"[(-1, 7, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/ratn...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/ppat...\" with entities \"[(-1, 11, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/dekt...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/bshi...\" with entities \"[(-1, 23, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/dris...\" with entities \"[(-1, 13, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/suga...\" with entities \"[(-1, 14, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/rajv...\" with entities \"[(-1, 14, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/rdeb...\" with entities \"[(-1, 13, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/vnir...\" with entities \"[(-1, 9, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/dsuh...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/cher...\" with entities \"[(-1, 11, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/gita...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/rmah...\" with entities \"[(-1, 13, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/gave...\" with entities \"[(-1, 15, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/prav...\" with entities \"[(-1, 16, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/odot...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/rbar...\" with entities \"[(-1, 8, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/elan...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/dana...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/dgod...\" with entities \"[(-1, 7, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/raja...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/deva...\" with entities \"[(-1, 19, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/vyan...\" with entities \"[(-1, 14, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/mtul...\" with entities \"[(-1, 16, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/bawa...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/anig...\" with entities \"[(-1, 13, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/phal...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/sshi...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/dnaa...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/tara...\" with entities \"[(-1, 14, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/hsen...\" with entities \"[(-1, 13, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/roja...\" with entities \"[(-1, 9, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/zara...\" with entities \"[(-1, 11, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/atif...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/cwat...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/atis...\" with entities \"[(-1, 11, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/dshi...\" with entities \"[(-1, 14, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/amac...\" with entities \"[(-1, 13, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/mhar...\" with entities \"[(-1, 15, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/shub...\" with entities \"[(-1, 15, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/shro...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/uvam...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/such...\" with entities \"[(-1, 15, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/daga...\" with entities \"[(-1, 13, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/zarn...\" with entities \"[(-1, 9, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/psri...\" with entities \"[(-1, 13, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/jiya...\" with entities \"[(-1, 13, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/upam...\" with entities \"[(-1, 14, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/kson...\" with entities \"[(-1, 15, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/anwa...\" with entities \"[(-1, 8, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/eshm...\" with entities \"[(-1, 14, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/pris...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/tfai...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/khok...\" with entities \"[(-1, 14, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/prak...\" with entities \"[(-1, 13, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/dram...\" with entities \"[(-1, 14, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/nive...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/zami...\" with entities \"[(-1, 9, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/vine...\" with entities \"[(-1, 11, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/apar...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/deva...\" with entities \"[(-1, 14, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/kjas...\" with entities \"[(-1, 14, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/sans...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/seth...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/etae...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/gamu...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/vija...\" with entities \"[(-1, 20, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/twad...\" with entities \"[(-1, 14, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/umme...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/nimi...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/annu...\" with entities \"[(-1, 14, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/dipa...\" with entities \"[(-1, 14, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/gunt...\" with entities \"[(-1, 8, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/neel...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/dkan...\" with entities \"[(-1, 11, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/zgut...\" with entities \"[(-1, 9, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/manv...\" with entities \"[(-1, 16, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/ishp...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/deva...\" with entities \"[(-1, 18, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/bhad...\" with entities \"[(-1, 15, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/tamr...\" with entities \"[(-1, 12, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/dinu...\" with entities \"[(-1, 13, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/azan...\" with entities \"[(-1, 11, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/luth...\" with entities \"[(-1, 11, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/meen...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Contact Info: Emails: https://linkedin.com/in/spal...\" with entities \"[(-1, 10, 'PERSON')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "examples = []\n",
        "for text, annotations in TRAIN_DATA:\n",
        "    # TEXT = text.lower()\n",
        "    example = Example.from_dict(nlp.make_doc(text), annotations)\n",
        "    examples.append(example)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "P4ulcVy1VVs0"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_6HNZDdQNDX",
        "outputId": "06140d0d-e022-404b-af75-8f7dbac0ea13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses at epoch 0: {'ner': np.float32(9.175439e-18)}\n",
            "Losses at epoch 1: {'ner': np.float32(3.6158162e-17)}\n",
            "Losses at epoch 2: {'ner': np.float32(2.0112655e-17)}\n",
            "Losses at epoch 3: {'ner': np.float32(1.691328e-17)}\n",
            "Losses at epoch 4: {'ner': np.float32(1.7137406e-16)}\n"
          ]
        }
      ],
      "source": [
        "pipe_exceptions = [\"ner\"]\n",
        "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "\n",
        "# Start updating only the NER\n",
        "with nlp.disable_pipes(*unaffected_pipes):\n",
        "    optimizer = nlp.resume_training()\n",
        "    for epoch in range(5):\n",
        "        random.shuffle(examples)  # Shuffle the precomputed examples\n",
        "        losses = {}\n",
        "        for example in examples:\n",
        "            nlp.update([example], sgd=optimizer, losses=losses)\n",
        "        print(f\"Losses at epoch {epoch}: {losses}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu3mfOIwO7l2",
        "outputId": "ee791a63-2774-4f7d-8661-443e11e2d968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "nlp.to_disk(\"person_only_model\")\n",
        "print(\"Model saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g-j5_mLcN8F",
        "outputId": "5cafb7b2-faa5-4a38-9f92-7a6b8de850b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: person_only_model/ (stored 0%)\n",
            "updating: person_only_model/lemmatizer/ (stored 0%)\n",
            "updating: person_only_model/lemmatizer/lookups/ (stored 0%)\n",
            "updating: person_only_model/lemmatizer/lookups/lookups.bin (deflated 56%)\n",
            "updating: person_only_model/vocab/ (stored 0%)\n",
            "updating: person_only_model/vocab/key2row (stored 0%)\n",
            "updating: person_only_model/vocab/strings.json (deflated 77%)\n",
            "updating: person_only_model/vocab/vectors.cfg (stored 0%)\n",
            "updating: person_only_model/vocab/vectors (deflated 45%)\n",
            "updating: person_only_model/vocab/lookups.bin (deflated 43%)\n",
            "updating: person_only_model/config.cfg (deflated 73%)\n",
            "updating: person_only_model/tok2vec/ (stored 0%)\n",
            "updating: person_only_model/tok2vec/cfg (stored 0%)\n",
            "updating: person_only_model/tok2vec/model (deflated 7%)\n",
            "updating: person_only_model/tokenizer (deflated 81%)\n",
            "updating: person_only_model/ner/ (stored 0%)\n",
            "updating: person_only_model/ner/moves (deflated 76%)\n",
            "updating: person_only_model/ner/cfg (deflated 33%)\n",
            "updating: person_only_model/ner/model (deflated 7%)\n",
            "updating: person_only_model/senter/ (stored 0%)\n",
            "updating: person_only_model/senter/cfg (stored 0%)\n",
            "updating: person_only_model/senter/model (deflated 9%)\n",
            "updating: person_only_model/tagger/ (stored 0%)\n",
            "updating: person_only_model/tagger/cfg (deflated 64%)\n",
            "updating: person_only_model/tagger/model (deflated 8%)\n",
            "updating: person_only_model/attribute_ruler/ (stored 0%)\n",
            "updating: person_only_model/attribute_ruler/patterns (deflated 83%)\n",
            "updating: person_only_model/parser/ (stored 0%)\n",
            "updating: person_only_model/parser/moves (deflated 55%)\n",
            "updating: person_only_model/parser/cfg (deflated 32%)\n",
            "updating: person_only_model/parser/model (deflated 7%)\n",
            "updating: person_only_model/meta.json (deflated 69%)\n"
          ]
        }
      ],
      "source": [
        "! zip -r myfolder.zip person_only_model/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "Mskl17Lxd5eF"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('person_only_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "BulRPPT4SB9J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "BTSdIYzseuzZ"
      },
      "outputs": [],
      "source": [
        "text = 'Vivek ⋄vivkumar941121@gmail.com (mailto:vivkumar941121@gmail.com) ⋄Linkedin (https://www.linkedin.com/in/vivek-kumar-854b31231) ⋄Portfolio (https://vivek9411.github.io/) EDUCATION Institute of Engineering and Technology, Lucknow 2025 B.Tech- Computer Science and Engineering CGPA 8.38 Basubaral Public School, Bareilly , CBSE BOARD 2020 Intermediate - 93.60% SKILLS Languages C++, Python, HTML, CSS, SQL, Machine Learning Technical Skills Machine Learning, Data Structures and Algorithms, Problem Solving Soft Skills Leadership, Event Management, Teamwork Tools Visual Studio Code, M.S. Office, Git/GitHub, PyCharm PROJECTS University (https://github.com/Vivek9411/college-database-management-system) database (https://github.com/Vivek9411/college-database-management-system) management (https://github.com/Vivek9411/college-database-management-system) system (https://github.com/Vivek9411/college-database-management-system) Nov-Dec 2023 This web application efficiently manages university data across multiple states. Each student is assigned a Unique ID (UID) containing key attributes like state, college code, and admission year. This enables fast and efficient searching based on student attributes rather than scanning the entire database. It also reduces redundancy by implementing normalization. Tech Used:- Python, Django, SQL, HTML, CSS Exercise (https://github.com/Vivek9411/Exercise-Tracking-Tool..git) Tracking (https://github.com/Vivek9411/Exercise-Tracking-Tool..git) Tool. (https://github.com/Vivek9411/Exercise-Tracking-Tool..git) Sept 2023 A web application that helps users track their calorie intake and expenditure effortlessly. Users can log their meals and exercises using natural language (e.g., ”I ate 2 apples” or ”I ran for 30 minutes”), and the system will automatically convert these inputs into calories and store them in a database. Tech Used:- Python, Flask, SQL, NLP, Spacy PDF/WORD (https://github.com/Vivek9411/pdf-word-data-extractor) Data (https://github.com/Vivek9411/pdf-word-data-extractor) Extractor. (https://github.com/Vivek9411/pdf-word-data-extractor) May-2024 Extracting information from multiple PDF or DOCX files can be time-consuming. This project simplifies the task. This project aims to solve this problem by taking multiple PDF, DOCX, or both types of files at the same time, parsing them, and saving the email, mobile, and text information from the files into an Excel file as output. Tech Used:- Python, LLM, Flask, Py-Pdf, HTML, CSS ACHIEVEMENTS • Smart India Hackathon (SIH) -2023 Finalist Certificate (https://vivek9411.github.io/#testimonials) • Facebook Meta Hacker-cup 3452 Rank in round 2 Certificate (https://vivek9411.github.io/#testimonials) • Codechef START170B 144 Rank Contest (https://www.codechef.com/rankings/START170B?itemsPerPage=100&order=asc&page=1&search=vivekkumar1308&sortBy=rank) Link (https://www.codechef.com/rankings/START170B?itemsPerPage=100&order=asc&page=1&search=vivekkumar1308&sortBy=rank) • Four stars (1800+ rating) on Codechef Codechef (https://www.codechef.com/users/vivekkumar1308) • 700+ Question solved & Knight (1850+ rating) on Leetcode Leetcode (https://leetcode.com/Vivek_kumar9411/) • Codechef SQL Certificate Certificate (https://www.codechef.com/certificates/public/be1b99f) • Coursera Machine Learning Certificate (https://coursera.org/share/5fdcb11c97a3dfb8ee6266952469de53) CODING PROFILE HANDLES • Codechef vivek (https://www.codechef.com/users/vivekkumar1308) kumar (https://www.codechef.com/users/vivekkumar1308) • Codeforces vivek (https://codeforces.com/profile/vivek_.kumar) .kumar (https://codeforces.com/profile/vivek_.kumar) • leetcode Vivek (https://leetcode.com/Vivek_kumar9411/) kumar9411 (https://leetcode.com/Vivek_kumar9411/)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "5o9ap4GNe07A"
      },
      "outputs": [],
      "source": [
        "doc = nlp(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SE21ltnWe9IV",
        "outputId": "057b290a-75c3-4970-a94a-5c75164ef594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vivek ⋄vivkumar941121@gmail.com PERSON\n"
          ]
        }
      ],
      "source": [
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "NMPZ-XdzRRuF"
      },
      "outputs": [],
      "source": [
        "doc = nlp(text.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "x2y05-aiRTBS"
      },
      "outputs": [],
      "source": [
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu34sgfRfM2p",
        "outputId": "7c18f18b-e882-465b-81e6-3c9d3d0108ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Vikram Chatterjee', 'Aswathy Raghavan', 'Harshini Patel', 'Taramla', 'Gulshan Meda', 'Aisha Behera', 'Susheel Murty', 'Khare', 'Tank', 'Samay Debnath', 'Zilmil Kant', 'Prabir Khanna', 'Dyal', 'Rajput', 'Jasmit Athar', 'Sharvil Gaur', 'Monish Pathan', 'Rajveer Nag', 'Harjot Swain', 'Rajiv Ghose', 'Shubham Samaddar', 'Kahan Dani', 'Kayalvizhi Sundar', 'Sapna Sardar', 'Omya Bistagond', 'Akshat Dani', 'Hetvi Paighan', 'Behuria', 'Livdeep Ben', 'Malaimagal Sethi', 'Liyana', 'Kalpen Mody', 'Sanskriti Jamloki', 'Simran Bail', 'Faheem Quadiri', 'Shreyash Pillai', 'Osha Waseem', 'Aritra Talwar', 'Unni Dhawan', 'Sulochana Balkoty', 'Jiyu Reddy', 'Lusha Vora', 'Sanghvi', 'Raghwendra Jha', 'Arni Garg', 'Daiwik Suman', 'Tashi Buch', 'Soumyadeep Cheema', 'Laboni Meghwal', 'Virali Sondhi', 'Bhavini Mitra', 'Madhavan Srivastav', 'Vengatesh Sen', 'Barnawal', 'Rahi Jagaragallu', 'Fatahun Kisshan', 'Ganika Balmiki', 'Jeevika Asthana', 'Latifah Bal', 'Navya Meda', 'Aakshi Soni', 'Shyamali', 'Jignasa Kulsum', 'Chhavi Hasni', 'Chandani Rishiraj', 'Shamik Bhagat', 'Henish Tulshidas', 'Alani Thawani', 'Kaeya Nagoria', 'Deepak Kuruvilla', 'Srijit', 'Middinti', 'Narayan Bumb', 'Chirag Varghese', 'Prakash', 'Dada', 'Lanka', 'Bhadouriya', 'Gujrati', 'Shivang Khaliq', 'Ria Zacharia', 'Debyendu Veerepalli', 'Fariya Koshy', 'Ganapathy', 'Rai', 'Nagjibhai Sengupta', 'Saurav Manne', 'Arasi Pawar', 'Jahnavi Garg', 'Dalaja Mannan', 'Bhavani Dagade', 'Wali Choudhury', 'Tashi Bora', 'Nagesh Chakrabortty', 'Mannan', 'Shaarad Barnawal', 'Shubhang Sarnobat', 'Sabyasachi Dixit', 'Abhijoy', 'Usman Shere']\n"
          ]
        }
      ],
      "source": [
        "print(names[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGKPTZRNLdWx",
        "outputId": "02e5193c-5669-4a70-8756-f5dde0aabaac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses at epoch 0: {'ner': np.float32(9.882282)}\n",
            "Losses at epoch 1: {'ner': np.float32(9.64283)}\n",
            "Losses at epoch 2: {'ner': np.float32(5.7178893)}\n",
            "Losses at epoch 3: {'ner': np.float32(3.382425e-07)}\n",
            "Losses at epoch 4: {'ner': np.float32(1.959229e-08)}\n"
          ]
        }
      ],
      "source": [
        "pipe_exceptions = [\"ner\"]\n",
        "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "\n",
        "# Start updating only the NER\n",
        "with nlp.disable_pipes(*unaffected_pipes):\n",
        "    optimizer = nlp.resume_training()\n",
        "    for epoch in range(5):\n",
        "        random.shuffle(examples)  # Shuffle the precomputed examples\n",
        "        losses = {}\n",
        "        for example in examples:\n",
        "            nlp.update([example], sgd=optimizer, losses=losses)\n",
        "        print(f\"Losses at epoch {epoch}: {losses}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZMp70mB3R5f7",
        "outputId": "2da3f530-0bd7-4c38-9d74-92c1badbaa2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved!\n"
          ]
        }
      ],
      "source": [
        "nlp.to_disk(\"person_only_model\")\n",
        "print(\"Model saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUdydgS0R-FV",
        "outputId": "a833cdcf-c25e-4bf8-fab3-e69fdd3d649a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "updating: person_only_model/ (stored 0%)\n",
            "updating: person_only_model/lemmatizer/ (stored 0%)\n",
            "updating: person_only_model/lemmatizer/lookups/ (stored 0%)\n",
            "updating: person_only_model/lemmatizer/lookups/lookups.bin (deflated 56%)\n",
            "updating: person_only_model/vocab/ (stored 0%)\n",
            "updating: person_only_model/vocab/key2row (stored 0%)\n",
            "updating: person_only_model/vocab/strings.json (deflated 76%)\n",
            "updating: person_only_model/vocab/vectors.cfg (stored 0%)\n",
            "updating: person_only_model/vocab/vectors (deflated 45%)\n",
            "updating: person_only_model/vocab/lookups.bin (deflated 43%)\n",
            "updating: person_only_model/config.cfg (deflated 73%)\n",
            "updating: person_only_model/tok2vec/ (stored 0%)\n",
            "updating: person_only_model/tok2vec/cfg (stored 0%)\n",
            "updating: person_only_model/tok2vec/model (deflated 7%)\n",
            "updating: person_only_model/tokenizer (deflated 81%)\n",
            "updating: person_only_model/ner/ (stored 0%)\n",
            "updating: person_only_model/ner/moves (deflated 76%)\n",
            "updating: person_only_model/ner/cfg (deflated 33%)\n",
            "updating: person_only_model/ner/model (deflated 7%)\n",
            "updating: person_only_model/senter/ (stored 0%)\n",
            "updating: person_only_model/senter/cfg (stored 0%)\n",
            "updating: person_only_model/senter/model (deflated 9%)\n",
            "updating: person_only_model/tagger/ (stored 0%)\n",
            "updating: person_only_model/tagger/cfg (deflated 64%)\n",
            "updating: person_only_model/tagger/model (deflated 8%)\n",
            "updating: person_only_model/attribute_ruler/ (stored 0%)\n",
            "updating: person_only_model/attribute_ruler/patterns (deflated 83%)\n",
            "updating: person_only_model/parser/ (stored 0%)\n",
            "updating: person_only_model/parser/moves (deflated 55%)\n",
            "updating: person_only_model/parser/cfg (deflated 32%)\n",
            "updating: person_only_model/parser/model (deflated 7%)\n",
            "updating: person_only_model/meta.json (deflated 69%)\n"
          ]
        }
      ],
      "source": [
        "! zip -r myfolder.zip person_only_model/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk9gXgXnR-gn"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('person_only_model')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}